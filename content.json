{"pages":[],"posts":[{"title":"我的第一个神经网络——手写数字识别","text":"可从该页面获得的MNIST手写数字数据库具有60,000个示例的训练集和10,000个示例的测试集。它是NIST提供的更大集合的子集。数字已经过尺寸标准化，并以固定尺寸的图像为中心。 手写数字数据集THE MNIST DATABASE 123456789101112131415161718192021222324from keras.datasets import mnistfrom keras.utils import np_utilsfrom keras.optimizers import Adamfrom keras.models import Sequentialfrom keras.layers import Dense, Activation# 清洗数据def load_data(): global x_train, x_test, y_train, y_test x_train = x_train.reshape(x_train.shape[0], 28*28) x_test = x_test.reshape(x_test.shape[0], 28*28) x_train = x_train.astype('float32') x_test = x_test.astype('float32') y_train = np_utils.to_categorical(y_train, 10) y_test = np_utils.to_categorical(y_test, 10) x_train = x_train/255 x_test = x_test/255 return (x_train, y_train),(x_test, y_test)# 导入数据(x_train, y_train),(x_test, y_test) = mnist.load_data()(x_train, y_train),(x_test, y_test) = load_data() 12345678# 模型搭建model = Sequential()model.add(Dense(input_dim=28*28, units=500))model.add(Activation('relu'))model.add(Dense(units=500))model.add(Activation('relu'))model.add(Dense(units=10))model.add(Activation('softmax')) 1234# 模型配置model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) 1234# 训练model.fit(x_train, y_train, epochs=20, batch_size=100) Instructions for updating: Use tf.cast instead. Epoch 1/20 60000/60000 [==============================] - 5s 89us/step - loss: 0.2038 - acc: 0.9390 ... 60000/60000 [==============================] - 5s 86us/step - loss: 0.0051 - acc: 0.9985 Epoch 20/20 60000/60000 [==============================] - 5s 84us/step - loss: 0.0095 - acc: 0.9973 &lt;keras.callbacks.History at 0x103d9b710&gt; 1234# 训练评分score = model.evaluate(x_train, y_train, batch_size=100)print('Total loss in training set:', score[0])print('Accuracy in training set:', score[1]) 60000/60000 [==============================] - 2s 26us/step Total loss in training set: 0.030331732142293125 Accuracy in training set: 0.9930500061313311 1234# 测试评分score = model.evaluate(x_test, y_test, batch_size=100)print('Total loss in testing set:', score[0])print('Accuracy in testing set:', score[1]) 10000/10000 [==============================] - 0s 27us/step Total loss in testing set: 0.13895348183807527 Accuracy in testing set: 0.9754000073671341","link":"/2019/04/02/MNIST/"},{"title":"kaggle比赛初体验","text":"Hello,machine learning! kaggle链接 👉🏻请点我 步骤数据预处理用pandas读取训练集train.csv文件，并查看训练集维度训练集共42000张图片，每张图片像素为28*281234import pandas as pdtrain = pd.read_csv('train.csv')train.shape (42000, 785) 简单查看数据后发现第一列为label，分离出第一列为train_label其余为train_data，并对每个图片做标准化处理123train_label = train.iloc[:,0:1]train_data = train.iloc[:,1:]train_data = train_data/255 导入keras.utils模块中的np_utils，目的是使分类数据变为更容易处理的布尔值矩阵数据12from keras.utils import np_utilstrain_label = np_utils.to_categorical(train_label, 10) 模型搭建这里选择了使用了具有两个隐藏层的神经网络，每层500个神经元激活函数为Relu，输出函数为softmax123456789101112131415from keras.datasets import mnistfrom keras.optimizers import Adamfrom keras.models import Sequentialfrom keras.layers import Dense, Activationmodel = Sequential()model.add(Dense(input_dim=28*28, units=500))model.add(Activation('relu'))model.add(Dense(units=500))model.add(Activation('relu'))model.add(Dense(units=500))model.add(Activation('relu'))model.add(Dense(units=10))model.add(Activation('softmax')) 优化选择adam方法，代价函数采用了分类的交叉熵123model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) 开始训练123model.fit(train_data, train_label, epochs=20, batch_size=100) Epoch 1/20 42000/42000 [==============================] - 6s 142us/step - loss: 0.2332 - acc: 0.9297 Epoch 2/20 42000/42000 [==============================] - 6s 134us/step - loss: 0.0924 - acc: 0.9707 ... Epoch 20/20 42000/42000 [==============================] - 6s 139us/step - loss: 0.0124 - acc: 0.9966 测试集正确率为99.66%123score = model.evaluate(train_data, train_label, batch_size=100)print('Total loss in training set:', score[0])print('Accuracy in training set:', score[1]) 42000/42000 [==============================] - 2s 38us/step Total loss in training set: 0.012173209706547606 Accuracy in training set: 0.9963333366882233 创建预测文件读取待预测文件test.csv1test = pd.read_csv('test.csv') 开始预测12predict = model.predict(test)predict = predict.tolist() 将预测结果装入nparray12345678import numpy as nppre = np.array(np.zeros(28000)).reshape(28000,1).astype(np.int64)for i in range(28000): pre[i] = predict[i].index(max(predict[i]))index = np.array(np.arange(1,28001)).reshape(28000,1)result = np.hstack((index,pre)) 将DataFrame写入sample_submission.csv并上kaggle提交1234pd_data = pd.DataFrame(result,columns=['ImageId','Label'])pd_data.set_index('ImageId', inplace=True)print(pd_data[:10])pd_data.to_csv('sample_submission.csv') 大概长下面这个样子 👇🏻 Label ImageId 1 2 2 0 3 9 4 0 5 3 6 7 7 0 8 3 9 0 10 3 我的预测得分0.97700 完结撒花🎉🎉🎉","link":"/2019/04/10/hello ML/"},{"title":"Matplotlibn笔记📒","text":"12import matplotlib.pyplot as pltimport numpy as np 123x = np.linspace(1,10)y1 = 2*x + 1y2 = x**2 12345678910111213141516171819202122232425262728293031plt.figure(num = 3, figsize=(8,5))# x,y的标题plt.xlabel('$x$');plt.ylabel('$y$')plt.yticks([0,50,100], ['$bad$','$normal$','$good$'])# gca = get current axisax = plt.gca()ax.spines['right'].set_color('none')ax.spines['top'].set_color('none')ax.xaxis.set_ticks_position('bottom')ax.yaxis.set_ticks_position('left')# ax.spines['bottom'].set_position(('data',0))# ax.spines['left'].set_position(('data',0))l1, = plt.plot(x,y2,label = '$up$')l2, = plt.plot(x,y1,color='red',linewidth=1.0,linestyle='--',label='$down$')plt.legend(handles=[l1,l2],loc='best')# 注解x0 = 6y0 = x0**2plt.scatter(x0,y0,s=20) # 展示点plt.plot([x0,x0],[y0,0],'k--',lw=1)plt.annotate(r'$2x+1=%s$' % y0,xy=(x0,y0),xycoords='data',xytext=(8,30), arrowprops=dict(arrowstyle='-&gt;',connectionstyle='arc3,rad=.2'),color='pink')plt.text(2,50,r'$This\\ is\\ some\\ text.\\ \\mu\\ \\sigma_i\\ \\alpha_t$',fontdict={'size':12,'color':'red'})plt.show() 1234def f(x,y): return (1-x/2+x**5+y**3)*np.exp(-x**2-y**2)def z(x,y): return (x**2 + y**2) 123456789101112n = 256x = np.linspace(-3,3,n)y = np.linspace(-3,3,n)X,Y = np.meshgrid(x,y)plt.contourf(X,Y,f(X,Y),7,alpha=0.5,cmap=plt.cm.cool)C = plt.contour(X,Y,f(X,Y),7,colors='black')plt.clabel(C,inline=True,)plt.xticks(())plt.yticks(())plt.show() 1234a = np.random.normal(0,1,100).reshape((10,10))plt.imshow(a,interpolation='nearest')plt.colorbar(shrink=0.9)plt.show &lt;function matplotlib.pyplot.show(*args, **kw)&gt; 1from mpl_toolkits.mplot3d import Axes3D 12345678910fig = plt.figure()ax = Axes3D(fig)X = np.arange(-4,4,0.25)Y = np.arange(-4,4,0.25)X,Y = np.meshgrid(X,Y)R = np.sqrt(X**2+Y**2)ax.plot_surface(X,Y,R,cmap='rainbow')ax.contourf(X,Y,R,zdir='z',offset=0,cmap='rainbow')plt.show() 12345678910plt.figure()plt.subplot(2,3,4)plt.plot(np.arange(1,100))plt.subplot(2,3,5)plt.plot(np.arange(1,20)**2)plt.subplot(2,1,1)plt.plot(np.random.normal(0,1,100))plt.subplot(2,3,6)plt.plot(np.array(np.sin(np.arange(0,10,0.1))))plt.show() 1import matplotlib.gridspec as gridspec 1234567891011# plt.figure()# ax1 = plt.subplot2grid((3,3),(0,0),colspan=3,rowspan=1)# ax1.plot(np.random.normal(0,1,100))# ax1.set_title('time')# ax2 = plt.subplot2grid((3,3),(1,0),colspan=2,rowspan=1)# ax2 = plt.subplot2grid((3,3),(1,2),colspan=1,rowspan=2)# ax2 = plt.subplot2grid((3,3),(2,0),colspan=1,rowspan=1)# ax2 = plt.subplot2grid((3,3),(2,1),colspan=1,rowspan=1)# plt.show() 1234567# plt.figure()# gs = gridspec.GridSpec(3,3)# ax1 = plt.subplot(gs[0,:])# ax2 = plt.subplot(gs[1,:2])# ax3 = plt.subplot(gs[1:,2])# ax4 = plt.subplot(gs[-1,0])# ax5 = plt.subplot(gs[-1,1]) 123456789101112x = np.arange(0,50)y1 = np.random.normal(0,1,50)y2 = np.random.normal(1,2,50)fig,ax1 = plt.subplots()ax2 = ax1.twinx()ax1.plot(x,y1,'g-')ax2.plot(x,-y2,'b-')ax1.set_xlabel('X data')ax1.set_ylabel('Y1',color='g')ax2.set_ylabel('Y2',color='b')plt.show() 1from scipy.stats import t 12345x = np.arange(-5,5,0.1)plt.figure()plt.plot(x,t.pdf(x,2))plt.plot(x,t.pdf(x,10))plt.show() 12","link":"/2019/03/26/matplotlib/"},{"title":"Numpy笔记📒","text":"NumPy(Numerical Python) 是 Python 语言的一个扩展程序库，支持大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。123456import numpy as npl = [[1,2,3],[2,3,4]]# 列表转化成矩阵array = np.array(l)print(array) [[1 2 3] [2 3 4]] numpy的几种属性123456# 维度print('number of dim:',array.ndim)# 行数和列数print('shape :',array.shape) # 元素个数print('size:',array.size) number of dim: 2 shape : (2, 3) size: 6 创建array12a = np.array([2,3,4],dtype = np.int)print(a,a.dtype) [2 3 4] int64 123# 创建全0数组a = np.zeros((3,4),dtype = np.int16)print(a) [[0 0 0 0] [0 0 0 0] [0 0 0 0]] 123# 创建全1数组a = np.ones((3,4),dtype = np.int64)print(a) [[1 1 1 1] [1 1 1 1] [1 1 1 1]] 123# 创建全空数组a = np.empty((3,4),dtype = np.float)print(a) [[-1.49166815e-154 -1.49166815e-154 4.27255699e+180 6.12033286e+257] [ 3.83819517e+151 9.77368093e+165 1.03927302e-042 5.24049485e+174] [ 4.27796595e-033 5.81088333e+294 -1.49166815e-154 8.38743761e-309]] 123# 创建连续数组a = np.arange(1,13).reshape(3,4)print(a) [[ 1 2 3 4] [ 5 6 7 8] [ 9 10 11 12]] 123# 生成线段a = np.linspace(1,10,6).reshape(2,3)print(a) [[ 1. 2.8 4.6] [ 6.4 8.2 10. ]] 基础运算基本运算1数组运算12a = np.array([10,20,30,40])b = np.arange(4) 1a-b array([10, 19, 28, 37]) 1b**2 array([0, 1, 4, 9]) 1np.sin(a) array([-0.54402111, 0.91294525, -0.98803162, 0.74511316]) 1b&lt;3 array([ True, True, True, False]) 矩阵运算1234a = np.array([[1,2],[3,4]])b = np.arange(4).reshape(2,2)print(a)print(b) [[1 2] [3 4]] [[0 1] [2 3]] 1234# 对应元素相乘print(a*b)# 矩阵乘法print(np.dot(a,b)) [[ 0 2] [ 6 12]] [[ 4 7] [ 8 15]] 123456a = np.random.random((2,4))print(a)# axis=1时每行分别计算，axis=0时每列分别计算print('sum =',np.sum(a,axis=1))print('min =',np.min(a,axis=0))print('max =',np.max(a)) [[0.31357817 0.09926399 0.57284534 0.9692283 ] [0.86206853 0.94729865 0.80886452 0.01849844]] sum = [1.9549158 2.63673014] min = [0.31357817 0.09926399 0.57284534 0.01849844] max = 0.9692282997410551 基本运算212A = np.arange(2,14).reshape(3,4)print(A) [[ 2 3 4 5] [ 6 7 8 9] [10 11 12 13]] 12# 最小（大）值索引A.argmax() 11 1234# 平均值print(A.mean())# 对列求平均print(A.mean(axis=0)) 7.5 [6. 7. 8. 9.] 12# 中位数np.median(A) 7.5 12# 累加print(np.cumsum(A)) [ 2 5 9 14 20 27 35 44 54 65 77 90] 12# 累差print(np.diff(A)) [[1 1 1] [1 1 1] [1 1 1]] 12# 排序print(np.sort(A)) [[ 2 3 4 5] [ 6 7 8 9] [10 11 12 13]] 12# 转置print(np.transpose(A)) [[ 2 6 10] [ 3 7 11] [ 4 8 12] [ 5 9 13]] 12# A*ATprint(np.dot(A,A.T)) [[ 54 110 166] [110 230 350] [166 350 534]] 12# 滤波print(np.clip(A,5,9)) [[5 5 5 5] [6 7 8 9] [9 9 9 9]] 12# 铺平print(A.flatten()) [ 2 3 4 5 6 7 8 9 10 11 12 13] numpy索引12A = np.arange(3,15).reshape(3,4)print(A) [[ 3 4 5 6] [ 7 8 9 10] [11 12 13 14]] 12A[1,1]#A[1][1] 8 array合并1234A = np.array([1,1,1])B = np.array([2,2,2])np.vstack((A,B)) array([[1, 1, 1], [2, 2, 2]]) 1np.hstack((A,B)) array([1, 1, 1, 2, 2, 2]) array分割12A = np.arange(12).reshape(3,4)print(A) [[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11]] 12345np.split(A,3)# 横向分割# np.vsplit(A,3)# 纵向分割# np.hsplit(A,2) [array([[0, 1, 2, 3]]), array([[4, 5, 6, 7]]), array([[ 8, 9, 10, 11]])] 12# 不等量分割np.array_split(A,3,axis=1) [array([[0, 1], [4, 5], [8, 9]]), array([[ 2], [ 6], [10]]), array([[ 3], [ 7], [11]])] copy123a = np.array([1,2])# b.copy()没有关联性，为浅拷贝a is b.copy() False","link":"/2019/03/02/numpy/"},{"title":"scrapy入门","text":"安装1$ pip3 install scrapy 创建项目12$ cd desktop/tutorial$ scrapy startproject tutorial 创建爬虫123456789101112131415161718192021# 在tutorial/spiders目录下创建quotes_spider.py写入：import scrapyclass QuotesSpider(scrapy.Spider): name = \"quotes\" def start_requests(self): urls = [ 'http://quotes.toscrape.com/page/1/', 'http://quotes.toscrape.com/page/2/', ] for url in urls: yield scrapy.Request(url=url, callback=self.parse) def parse(self, response): page = response.url.split(\"/\")[-2] filename = 'quotes-%s.html' % page with open(filename, 'wb') as f: f.write(response.body) self.log('Saved file %s' % filename) 运行爬虫1$ scrapy crawl quotes 尝试使用shell调试1$ scrapy shell &apos;http://quotes.toscrape.com/page/1/&apos; 123# 可使用css和xpath进行匹配&gt;&gt;&gt; response.css('title::text').extract_first()'Quotes to Scrape'","link":"/2019/01/08/scrapy入门/"},{"title":"硬train的故事","text":"Thanks a lot, machine learning! Joel GrusFizz Buzz in Tensorflow","link":"/2019/03/30/video/"},{"title":"一道排序题","text":"给定一组数，每次只能交换两个数字的位置，求全部排序完成的最小交换次数 12345678910111213141516def s(l): k = 0 for i in range(len(l)): li = l[i:] j = li.index(min(li)) if j == 0: continue l[i], l[i+j] = l[i+j], l[i] k += 1 return kl = [5,4,3,2,1]print(s(l))# &gt;&gt;&gt; 2","link":"/2019/03/30/一道排序题/"},{"title":"Multithreading","text":"多线程GIL(Global Interpreter Lock)尽管Python完全支持多线程编程， 但是解释器的C语言实现部分在完全并行执行时并不是线程安全的。 实际上，解释器被一个全局解释器锁保护着，它确保任何时候都只有一个Python线程执行。 GIL最大的问题就是Python的多线程程序并不能利用多核CPU的优势 （比如一个使用了多个线程的计算密集型程序只会在一个单CPU上面运行）。 添加线程12345678import threading# 获取已激活的线程数threading.active_count()# 查看所有线程信息threading.enumerate()# 查看现在正在运行的线程threading.current_thread() 添加线程1234567891011def thread_job(): print('This is a thread of %s' % threading.current_thread())def main(): # 定义线程 thread = threading.Thread(target = thread_job) # 让线程开始工作 thread.start()if __name__ == '__main__': main() join所有线程运行结束后再执行主线程 储存线程结果到Queue1234567891011121314151617181920212223242526272829import threadingfrom queue import Queuedef job(l, q): for i in range(len(l)): l[i] = l[i] ** 2 q.put(l)def multithreading(): q = Queue() data = [[1, 2, 3], [3, 4, 5]] threads = [] for i in range(len(data)): t = threading.Thread(target=job, args=(data[i], q)) threads.append(t) t.start() for thread in threads: thread.join() result = [] for _ in range(len(data)): result.append(q.get()) print(result)if __name__ == '__main__': multithreading()## [[1, 4, 9], [9, 16, 25]] GIL测试我们创建一个 job, 分别用 threading 和 一般的方式执行这段程序. 并且创建一个 list 来存放我们要处理的数据. 在 Normal 的时候, 我们这个 list 扩展4倍, 在 threading 的时候, 我们建立4个线程, 并对运行时间进行对比.123456789101112131415161718192021222324252627282930313233343536373839import timeimport threadingfrom queue import Queueimport copydef job(l,q): res = sum(l) q.put(res)def multithreading(l): q = Queue() threads = [] for i in range(4): t = threading.Thread(target=job, args=(copy.copy(l),q)) t.start() threads.append(t) for thread in threads: thread.join() total = 0 for _ in range(4): total += q.get() print(total)def normal(l): res = sum(l*4) print(res)if __name__ == '__main__': l = list(range(1000000)) s_t = time.time() multithreading(l) print('multithreading: %ss' %(time.time()-s_t)) s_t = time.time() normal(l) print('normal: %ss' %(time.time()-s_t))## 1999998000000## multithreading: 0.06084728240966797s## 1999998000000## normal: 0.05951380729675293s 线程锁🔒12345lock = threading.Lock()# locklock.acquire()# releaselock.release()","link":"/2019/02/25/多线程/"},{"title":"Multiprocessing","text":"多进程创建进程1import multiprocessing as mp 1234567def job(): print('This is a process')if __name__ == '__main__': p1 = mp.Process(target = job) p1.start() p1.join() 把结果放在Queue中，参考多线程12# 不同点q = mp.Queue() 进程池pool进程池就是我们将所要运行的东西，放到池子里，Python会自行解决多进程的问题。1234567891011121314# 定义一个JOBdef job(x): return x*x# 接下来用map()获取结果，在map()中需要放入函数和需要迭代运算的值，然后它会自动分配给CPU核，返回结果def multicore(): # 定义一个POOL，可以自定义需要的核的数量 # processes=3 pool = mp.Pool() res = pool.map(job, range(10)) print(res) if __name__ == '__main__': multicore()## [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] 共享内存只有用共享内存才能让CPU之间有交流。123# 其中d和i参数用来设置数据类型的，d表示一个双精浮点类型，i表示一个带符号的整型。value1 = mp.Value('i', 0) value2 = mp.Value('d', 3.14) 进程锁🔒参考多线程","link":"/2019/02/26/多进程/"},{"title":"正则表达式","text":"RegEx 123456import re# []中为可以的字符print(re.search(r\"r[a-z]n\", 'dog runs to cat'))print(re.search(r\"r[0-9]n\", 'dog r4ns to cat'))print(re.search(r\"r[a-z0-9]n\", 'dog runs to cat')) &lt;_sre.SRE_Match object; span=(4, 7), match=&apos;run&apos;&gt; &lt;_sre.SRE_Match object; span=(4, 7), match=&apos;r4n&apos;&gt; &lt;_sre.SRE_Match object; span=(4, 7), match=&apos;run&apos;&gt; 特殊种类匹配数字1234# \\d 代表所有数字print(re.search(r\"r\\dn\", 'dog r3ns to cat'))# \\D 代表所有不是数字print(re.search(r\"r\\Dn\", 'dog runs to cat')) &lt;_sre.SRE_Match object; span=(4, 7), match=&apos;r3n&apos;&gt; &lt;_sre.SRE_Match object; span=(4, 7), match=&apos;run&apos;&gt; 空白1234# \\s 匹配所有空白符号[\\t\\n\\r\\f\\v]print(re.search(r\"r\\sn\", 'dog r\\nns to cat'))# \\S 匹配不是空白符号print(re.search(r\"r\\Sn\", 'dog runs to cat')) &lt;_sre.SRE_Match object; span=(4, 7), match=&apos;r\\nn&apos;&gt; &lt;_sre.SRE_Match object; span=(4, 7), match=&apos;run&apos;&gt; 所有字母数字和”_”1234# \\w : [0-9a-zA-Z_]print(re.search(r\"r\\wn\", 'dog runs to cat'))# \\W opposite to \\wprint(re.search(r\"r\\Wn\", 'dog runs to cat')) &lt;_sre.SRE_Match object; span=(4, 7), match=&apos;run&apos;&gt; None 空格1234# \\b 紧贴着字符的空白字符print(re.search(r\"\\bruns\\b\", 'dog runs to cat'))# \\B 无需紧贴着print(re.search(r\"\\B runs \\B\", 'dog runs to cat')) &lt;_sre.SRE_Match object; span=(4, 8), match=&apos;runs&apos;&gt; &lt;_sre.SRE_Match object; span=(4, 10), match=&apos; runs &apos;&gt; 特殊字符和任意字符1234# \\\\print(re.search(r\"runs\\\\\", 'dog runs\\ to cat'))# . 除了\\n都可以匹配print(re.search(r\"r.ns\", 'dog r[ns to cat')) &lt;_sre.SRE_Match object; span=(4, 9), match=&apos;runs\\\\&apos;&gt; &lt;_sre.SRE_Match object; span=(4, 8), match=&apos;r[ns&apos;&gt; 句首句尾1234# ^ 句首print(re.search(r\"^dog\", 'dog runs to cat'))# $ 句尾print(re.search(r\"cat$\", 'dog runs to cat')) &lt;_sre.SRE_Match object; span=(0, 3), match=&apos;dog&apos;&gt; &lt;_sre.SRE_Match object; span=(12, 15), match=&apos;cat&apos;&gt; 是否123# ？print(re.search(r\"Mon(day)?\", 'Monday'))print(re.search(r\"Mon(day)?\", 'Mon')) &lt;_sre.SRE_Match object; span=(0, 6), match=&apos;Monday&apos;&gt; &lt;_sre.SRE_Match object; span=(0, 3), match=&apos;Mon&apos;&gt; 多行匹配123456# multi-linestring = '''Dog runs to cat.I run to dog.'''print(re.search(r\"^I\", string, flags=re.M)) &lt;_sre.SRE_Match object; span=(18, 19), match=&apos;I&apos;&gt; 0或多次 1或多次1234567# * 0或多次print(re.search(r\"ab*\", \"a\"))print(re.search(r\"ab*\", \"abbbbbbb\"))# + 1或多次print(re.search(r\"ab+\", \"a\"))print(re.search(r\"ab+\", \"abbbbbbb\")) &lt;_sre.SRE_Match object; span=(0, 1), match=&apos;a&apos;&gt; &lt;_sre.SRE_Match object; span=(0, 8), match=&apos;abbbbbbb&apos;&gt; None &lt;_sre.SRE_Match object; span=(0, 8), match=&apos;abbbbbbb&apos;&gt; 可选次数1234# {m,n} 可选次数print(re.search(r\"ab{2,10}\", \"a\"))print(re.search(r\"ab{2,7}\", \"abbbbbb\"))print(re.search(r\"ab{6}\", \"abbbbbb\")) None &lt;_sre.SRE_Match object; span=(0, 7), match=&apos;abbbbbb&apos;&gt; &lt;_sre.SRE_Match object; span=(0, 7), match=&apos;abbbbbb&apos;&gt; GROUP组12345678910# groupmatch = re.search(r\"(\\d+), Data: (.+)\", \"ID: 123456 Data: Jan/8/2019\")# print(match.group())# print(match.group(1))# print(match.group(2))# 自定义组名match = re.search(r\"(?P&lt;id&gt;\\d+), Data: (?P&lt;data&gt;.+)\", \"ID: 123456 Data: Jan/8/2019\")# print(match.group(id))# print(match.group(data)) 寻找所有匹配12345# findallprint(re.findall(r\"r.n\", \"ran run ren\"))# | : orprint(re.findall(r\"(ran|run)\", \"ran run ren\")) [&apos;ran&apos;, &apos;run&apos;, &apos;ren&apos;] [&apos;ran&apos;, &apos;run&apos;] 替换12# re.sub 替换print(re.sub(r\"r[ua]ns\", \"catches\", \"Dog runs to cat.\")) Dog catches to cat. 分裂12# re.splitprint(re.split(r\"[;,\\.]\", \"a;b,c.d;e\")) [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;] Compile123# Compilecompile_re = re.compile(r\"r[au]ns\")print(compile_re.search(\"Dog runs to cat.\")) &lt;_sre.SRE_Match object; span=(4, 8), match=&apos;runs&apos;&gt;","link":"/2019/01/08/正则表达式/"},{"title":"留言板 📮","text":"欢迎留下评论～","link":"/2000/03/02/留言板/"},{"title":"Keras手把手教学之 💯","text":"Keras Sequential 顺序模型 模型搭建直接看例子点这里 👈🏻 Sequential 模型是层的线性堆栈 12345678910111213141516import kerasfrom keras.models import Sequentialfrom keras.layers import Dense, Activationmodel = Sequential()# Dense: fully connection(DNN密集型神经网络)model.add(Dense(input_dim=28*28,units=500))# activation function:# softplus, softsign, relu, tanh, hard_sigmoid, linearmodel.add(Activation('sigmoid'))# the second hidden layermodel.add(Dense(units=500))model.add(Activation('sigmoid'))model.add(Dense(units=10))model.add(Activation('softmax')) 模型配置在训练模型之前，您需要配置学习过程，这是通过 compile 方法完成的。它接收三个参数： 优化器 optimizer。它可以是现有优化器的字符串标识符，如 rmsprop 或 adagrad，也可以是 Optimizer 类的实例。 损失函数 loss，模型试图最小化的目标函数。它可以是现有损失函数的字符串标识符，如 categorical_crossentropy 或 mse，也可以是一个目标函数。 评估标准 metrics。对于任何分类问题，你都希望将其设置为 metrics = ['accuracy']。 123456789101112131415161718# 二分类问题model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])# 均方误差回归问题model.compile(optimizer='rmsprop', loss='mse')# 自定义评估标准函数import keras.backend as Kdef mean_pred(y_true, y_pred): return K.mean(y_pred)model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy', mean_pred]) 123456# step 3.1:# Configuration# optimizer = [SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam]model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) 模型训练Keras 模型在输入数据和标签的 Numpy 矩阵上进行训练。为了训练一个模型，你通常会使用 fit 函数。 1234567# 具有 10 个类的单输入模型（多分类分类）：# 生成虚拟数据import numpy as npdata = np.random.random((50000, 28*28))labels = np.random.randint(10, size=(50000, 1))# 将标签转换为分类的 one-hot 编码one_hot_labels = keras.utils.to_categorical(labels, num_classes=10) 1234567891011# step 3.2:# Find the optimal network parameters# do not really minimize total loss# betch_size:# --&gt; pick the 1st batch L' = L1 + L31 + ...# update parameters once# --&gt; pick the 2nd batch ...# all of the betch make one epoch: need 20 epoch# when beach_size = 1:# Stochastic gradient descentmodel.fit(data, one_hot_labels, epochs=20, batch_size=100) Epoch 1/20 50000/50000 [==============================] - 4s 84us/step - loss: 2.3052 - acc: 0.1004 Epoch 2/20 50000/50000 [==============================] - 5s 92us/step - loss: 2.3046 - acc: 0.1019 Epoch 3/20 50000/50000 [==============================] - 4s 87us/step - loss: 2.3053 - acc: 0.0997 Epoch 4/20 50000/50000 [==============================] - 4s 84us/step - loss: 2.3057 - acc: 0.1014 Epoch 5/20 50000/50000 [==============================] - 5s 92us/step - loss: 2.3057 - acc: 0.1027 Epoch 6/20 50000/50000 [==============================] - 5s 91us/step - loss: 2.3065 - acc: 0.1035 Epoch 7/20 50000/50000 [==============================] - 4s 84us/step - loss: 2.3077 - acc: 0.1034 Epoch 8/20 50000/50000 [==============================] - 5s 94us/step - loss: 2.3081 - acc: 0.1039 Epoch 9/20 50000/50000 [==============================] - 4s 89us/step - loss: 2.3057 - acc: 0.1109 Epoch 10/20 50000/50000 [==============================] - 4s 87us/step - loss: 2.3012 - acc: 0.1190 Epoch 11/20 50000/50000 [==============================] - 4s 87us/step - loss: 2.2925 - acc: 0.1285 Epoch 12/20 50000/50000 [==============================] - 4s 88us/step - loss: 2.2836 - acc: 0.1375 Epoch 13/20 50000/50000 [==============================] - 4s 84us/step - loss: 2.2744 - acc: 0.1476 Epoch 14/20 50000/50000 [==============================] - 4s 86us/step - loss: 2.2675 - acc: 0.1526 Epoch 15/20 50000/50000 [==============================] - 4s 85us/step - loss: 2.2638 - acc: 0.1551 Epoch 16/20 50000/50000 [==============================] - 4s 80us/step - loss: 2.2556 - acc: 0.1602 Epoch 17/20 50000/50000 [==============================] - 4s 83us/step - loss: 2.2525 - acc: 0.1638 Epoch 18/20 50000/50000 [==============================] - 5s 94us/step - loss: 2.2534 - acc: 0.1617 Epoch 19/20 50000/50000 [==============================] - 5s 93us/step - loss: 2.2462 - acc: 0.1681 Epoch 20/20 50000/50000 [==============================] - 4s 83us/step - loss: 2.2403 - acc: 0.1694 &lt;keras.callbacks.History at 0x126444278&gt; Example基于多层感知器 (MLP) 的 softmax 多分类（分类器）： 123456789101112131415import kerasfrom keras.models import Sequentialfrom keras.layers import Dense, Dropout, Activationfrom keras.optimizers import SGD# 生成虚拟数据import numpy as np# 1000行*20列 的区间在[0.,1.)的浮点数x_train = np.random.random((1000, 20))# 生成 1000行*1列 的区间在[0-10)的整数，随后转化为分类的 one-hot 编码（1000行*10列 的(0,1)矩阵）y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)# 100行*20列 的测试集x_test = np.random.random((100, 20))# 100行*10列 的测试标签y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10) 123456789model = Sequential()# Dense(64) 是一个具有 64 个隐藏神经元的全连接层。# 在第一层必须指定所期望的输入数据尺寸：# 在这里，是一个 20 维的向量。model.add(Dense(units=64, activation='relu', input_dim=20))model.add(Dropout(rate=0.5))model.add(Dense(units=64, activation='relu'))model.add(Dropout(rate=0.5))model.add(Dense(units=10, activation='softmax')) 123456# 优化器sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)# 模型配置model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy']) 1234# 模型训练model.fit(x_train, y_train, epochs=20, batch_size=128) Epoch 1/20 1000/1000 [==============================] - 0s 402us/step - loss: 2.4034 - acc: 0.1010 Epoch 2/20 1000/1000 [==============================] - 0s 19us/step - loss: 2.3808 - acc: 0.0920 Epoch 3/20 1000/1000 [==============================] - 0s 22us/step - loss: 2.3396 - acc: 0.1120 Epoch 4/20 1000/1000 [==============================] - 0s 23us/step - loss: 2.3249 - acc: 0.1190 Epoch 5/20 1000/1000 [==============================] - 0s 20us/step - loss: 2.3356 - acc: 0.0980 Epoch 6/20 1000/1000 [==============================] - 0s 22us/step - loss: 2.3233 - acc: 0.1210 Epoch 7/20 1000/1000 [==============================] - 0s 18us/step - loss: 2.3070 - acc: 0.1080 Epoch 8/20 1000/1000 [==============================] - 0s 22us/step - loss: 2.3190 - acc: 0.1030 Epoch 9/20 1000/1000 [==============================] - 0s 22us/step - loss: 2.3112 - acc: 0.0900 Epoch 10/20 1000/1000 [==============================] - 0s 20us/step - loss: 2.3076 - acc: 0.0960 Epoch 11/20 1000/1000 [==============================] - 0s 15us/step - loss: 2.3067 - acc: 0.1060 Epoch 12/20 1000/1000 [==============================] - 0s 16us/step - loss: 2.3058 - acc: 0.1160 Epoch 13/20 1000/1000 [==============================] - 0s 16us/step - loss: 2.2988 - acc: 0.1180 Epoch 14/20 1000/1000 [==============================] - 0s 17us/step - loss: 2.3008 - acc: 0.1240 Epoch 15/20 1000/1000 [==============================] - 0s 20us/step - loss: 2.3036 - acc: 0.1090 Epoch 16/20 1000/1000 [==============================] - 0s 22us/step - loss: 2.3042 - acc: 0.1060 Epoch 17/20 1000/1000 [==============================] - 0s 18us/step - loss: 2.3016 - acc: 0.1070 Epoch 18/20 1000/1000 [==============================] - 0s 25us/step - loss: 2.3054 - acc: 0.1390 Epoch 19/20 1000/1000 [==============================] - 0s 39us/step - loss: 2.2960 - acc: 0.1200 Epoch 20/20 1000/1000 [==============================] - 0s 34us/step - loss: 2.3021 - acc: 0.0940 &lt;keras.callbacks.History at 0x1842de6b38&gt; 12# 模型评分score = model.evaluate(x_test, y_test, batch_size=128) 100/100 [==============================] - 0s 13us/step","link":"/2019/03/27/keras notebook/"},{"title":"SQL","text":"SQL SQL 指结构化查询语言 SQL 使我们有能力访问数据库 SQL 是一种 ANSI 的标准计算机语言 RDBMS - 关系数据库管理系统（Relational Database Management System） DML 和 DDL可以把 SQL 分为两个部分：数据操作语言 (DML) 和 数据定义语言 (DDL)。SQL (结构化查询语言)是用于执行查询的语法。但是 SQL 语言也包含用于更新、插入和删除记录的语法。 查询和更新指令构成了 SQL 的 DML 部分： SELECT - 从数据库表中获取数据 UPDATE - 更新数据库表中的数据 DELETE - 从数据库表中删除数据 INSERT INTO - 向数据库表中插入数据 SQL 的数据定义语言 (DDL) 部分使我们有能力创建或删除表格。我们也可以定义索引（键），规定表之间的链接，以及施加表间的约束。 SQL 中最重要的 DDL 语句: CREATE DATABASE - 创建新数据库 ALTER DATABASE - 修改数据库 CREATE TABLE - 创建新表 ALTER TABLE - 变更（改变）数据库表 DROP TABLE - 删除表 CREATE INDEX - 创建索引（搜索键） DROP INDEX - 删除索引 SELECT语句SELECT12# SELECT 列名称 FROM 表名称SELECT * FROM students; SELECT DISTINCT123# 用于返回唯一不同的值# SELECT DISTINCT 列名称 FROM 表名称SELECT DISTINCT Company FROM Orders ; WHERE1# SELECT 列名称 FROM 表名称 WHERE 列 运算符 值 ORDER BY1SELECT Company, OrderNumber FROM Orders ORDER BY Company DESC, OrderNumber ASC; INSERT INTO123# INSERT INTO table_name (列1, 列2,...) VALUES (值1, 值2,....)INSERT INTO Persons VALUES ('Gates', 'Bill', 'Xuanwumen 10', 'Beijing');INSERT INTO Persons (LastName, Address) VALUES ('Wilson', 'Champs-Elysees'); UPDATE12345# UPDATE 表名称 SET 列名称 = 新值 WHERE 列名称 = 某值# 我们为 lastname 是 \"Wilson\" 的人添加 firstname：UPDATE Person SET FirstName = 'Fred' WHERE LastName = 'Wilson' # 我们会修改地址（address），并添加城市名称（city）：UPDATE Person SET Address = 'Zhongshan 23', City = 'Nanjing' WHERE LastName = 'Wilson' DELETE123456# 删除行# DELETE FROM 表名称 WHERE 列名称 = 值DELETE FROM Person WHERE LastName = 'Wilson' # 删除所有行DELETE FROM table_nameDELETE * FROM table_name 高级TOP1234# 我们希望从上面的 \"Persons\" 表中选取头两条记录SELECT TOP 2 * FROM Persons# 我们希望从上面的 \"Persons\" 表中选取 50% 的记录SELECT TOP 50 PERCENT * FROM Persons LIKELIKE 操作符用于在 WHERE 子句中搜索列中的指定模式12345# 从上面的 \"Persons\" 表中选取居住在以 \"N\" 开始的城市里的人：SELECT * FROM Persons WHERE City LIKE 'N%'# \"%\" 可用于定义通配符（模式中缺少的字母）# 从 \"Persons\" 表中选取居住在不包含 \"lon\" 的城市里的人：SELECT * FROM Persons WHERE City NOT LIKE '%lon%' 通配符123# 从上面的 \"Persons\" 表中选取居住的城市不以 \"A\" 或 \"L\" 或 \"N\" 开头的人：SELECT * FROM PersonsWHERE City LIKE '[!ALN]%' ININ 操作符允许我们在 WHERE 子句中规定多个值123# 从上表中选取姓氏为 Adams 和 Carter 的人：SELECT * FROM PersonsWHERE LastName IN ('Adams','Carter') BETWEENBETWEEN 操作符在 WHERE 子句中使用，作用是选取介于两个值之间的数据范围。12345678# 以字母顺序显示介于 \"Adams\"（包括）和 \"Carter\"（不包括）之间的人，请使用下面的 SQL：SELECT * FROM PersonsWHERE LastNameBETWEEN 'Adams' AND 'Carter'# 使用上面的例子显示范围之外的人，请使用 NOT 操作符：SELECT * FROM PersonsWHERE LastNameNOT BETWEEN 'Adams' AND 'Carter' 使用别名12SELECT LastName AS Family, FirstName AS NameFROM Persons JOINjoin 用于根据两个或多个表中的列之间的关系，从这些表中查询数据。 先确定主表，仍然使用FROM &lt;表1&gt;的语法； 再确定需要连接的表，使用INNER JOIN &lt;表2&gt;的语法； 然后确定连接条件，使用ON &lt;条件…&gt;，这里的条件是s.class_id = c.id，表示students表的class_id列与classes表的id列相同的行需要连接； 可选：加上WHERE子句、ORDER BY等子句。123456# 列出所有人的定购，可以使用下面的 SELECT 语句：SELECT Persons.LastName, Persons.FirstName, Orders.OrderNoFROM PersonsINNER JOIN OrdersON Persons.Id_P = Orders.Id_PORDER BY Persons.LastName UNIONUNION 操作符用于合并两个或多个 SELECT 语句的结果集12345# 列出所有在中国和美国的不同的雇员名：SELECT E_Name FROM Employees_ChinaUNIONSELECT E_Name FROM Employees_USA# UNION ALL 允许重复 SELECT INTO SELECT INTO 语句可用于创建表的备份复件 SELECT INTO 语句从一个表中选取数据，然后把数据插入另一个表中。 SELECT INTO 语句常用于创建表的备份复件或者用于对记录进行存档。12345678910# 备份SELECT *INTO Persons_backupFROM Persons# 创建一个名为 \"Persons_Order_Backup\" 的新表，其中包含了从 Persons 和 Orders 两个表中取得的信息：SELECT Persons.LastName,Orders.OrderNoINTO Persons_Order_BackupFROM PersonsINNER JOIN OrdersON Persons.Id_P = Orders.Id_P CREATE DATABASE12# 创建数据库CREATE DATABASE my_db CREATE TABLE12345678CREATE TABLE Persons(Id_P int,LastName varchar(255),FirstName varchar(255),Address varchar(255),City varchar(255)) 约束 (Constraints) NOT NULL UNIQUE PRIMARY KEY FOREIGN KEY CHECK DEFAULT NOT NULL123456789# 强制列不接受 NULL 值CREATE TABLE Persons(Id_P int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255)) UNIQUE123456789CREATE TABLE Persons(Id_P int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255),UNIQUE (Id_P)) 当表已被创建时，如需在 “Id_P” 列创建 UNIQUE 约束，请使用下列 SQL：12ALTER TABLE PersonsADD UNIQUE (Id_P) PRIMARY KEY PRIMARY KEY 约束唯一标识数据库表中的每条记录。 主键必须包含唯一的值。 主键列不能包含 NULL 值。 每个表都应该有一个主键，并且每个表只能有一个主键。123456789CREATE TABLE Persons(Id_P int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255),PRIMARY KEY (Id_P)) 如果在表已存在的情况下为 “Id_P” 列创建 PRIMARY KEY 约束，请使用下面的 SQL：12ALTER TABLE PersonsADD PRIMARY KEY (Id_P) DEFAULTDEFAULT 约束用于向列中插入默认值。12345678CREATE TABLE Persons(Id_P int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255) DEFAULT 'Sandnes') CREATE INDEX CREATE INDEX 语句用于在表中创建索引。 在不读取整个表的情况下，索引使数据库应用程序可以更快地查找数据。123456# 在表上创建一个简单的索引。允许使用重复的值：CREATE INDEX index_nameON table_name (column_name)# 在表上创建一个唯一的索引CREATE UNIQUE INDEX index_nameON table_name (column_name) DROP通过使用 DROP 语句，可以轻松地删除索引、表和数据库。1234DROP TABLE 表名称DROP DATABASE 数据库名称使用 TRUNCATE TABLE 命令（仅仅删除表格中的数据）：TRUNCATE TABLE 表名称 ALTER TABLEALTER TABLE 语句用于在已有的表中添加、修改或删除列。123456789# 如需在表中添加列，请使用下列语法:ALTER TABLE table_nameADD column_name datatype# 要删除表中的列，请使用下列语法：ALTER TABLE table_name DROP COLUMN column_name# 要改变表中列的数据类型，请使用下列语法：ALTER TABLE table_nameALTER COLUMN column_name datatype 123# 在表 \"Persons\" 中添加一个名为 \"Birthday\" 的新列ALTER TABLE PersonsADD Birthday date AUTO INCREMENTAuto-increment 会在新记录插入表中时生成一个唯一的数字。12345678910# 把 \"Persons\" 表中的 \"P_Id\" 列定义为 auto-increment 主键：CREATE TABLE Persons(P_Id int NOT NULL AUTO_INCREMENT,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255),PRIMARY KEY (P_Id)) VIEW视图是基于 SQL 语句的结果集的可视化的表。 NULL123# 选取在 \"Address\" 列中带有 NULL 值的记录:SELECT LastName,FirstName,Address FROM PersonsWHERE Address IS NULL","link":"/2019/02/21/sql/"}],"tags":[{"name":"机器学习","slug":"机器学习","link":"/tags/机器学习/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"算法","slug":"算法","link":"/tags/算法/"},{"name":"SQL","slug":"SQL","link":"/tags/SQL/"}],"categories":[{"name":"machine learning","slug":"machine-learning","link":"/categories/machine-learning/"},{"name":"Kaggle","slug":"Kaggle","link":"/categories/Kaggle/"},{"name":"python","slug":"python","link":"/categories/python/"},{"name":"算法","slug":"算法","link":"/categories/算法/"}]}
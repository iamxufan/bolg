{"pages":[],"posts":[{"title":"æˆ‘çš„ç¬¬ä¸€ä¸ªç¥ç»ç½‘ç»œâ€”â€”æ‰‹å†™æ•°å­—è¯†åˆ«","text":"å¯ä»è¯¥é¡µé¢è·å¾—çš„MNISTæ‰‹å†™æ•°å­—æ•°æ®åº“å…·æœ‰60,000ä¸ªç¤ºä¾‹çš„è®­ç»ƒé›†å’Œ10,000ä¸ªç¤ºä¾‹çš„æµ‹è¯•é›†ã€‚å®ƒæ˜¯NISTæä¾›çš„æ›´å¤§é›†åˆçš„å­é›†ã€‚æ•°å­—å·²ç»è¿‡å°ºå¯¸æ ‡å‡†åŒ–ï¼Œå¹¶ä»¥å›ºå®šå°ºå¯¸çš„å›¾åƒä¸ºä¸­å¿ƒã€‚ æ‰‹å†™æ•°å­—æ•°æ®é›†THE MNIST DATABASE 123456789101112131415161718192021222324from keras.datasets import mnistfrom keras.utils import np_utilsfrom keras.optimizers import Adamfrom keras.models import Sequentialfrom keras.layers import Dense, Activation# æ¸…æ´—æ•°æ®def load_data(): global x_train, x_test, y_train, y_test x_train = x_train.reshape(x_train.shape[0], 28*28) x_test = x_test.reshape(x_test.shape[0], 28*28) x_train = x_train.astype('float32') x_test = x_test.astype('float32') y_train = np_utils.to_categorical(y_train, 10) y_test = np_utils.to_categorical(y_test, 10) x_train = x_train/255 x_test = x_test/255 return (x_train, y_train),(x_test, y_test)# å¯¼å…¥æ•°æ®(x_train, y_train),(x_test, y_test) = mnist.load_data()(x_train, y_train),(x_test, y_test) = load_data() 12345678# æ¨¡å‹æ­å»ºmodel = Sequential()model.add(Dense(input_dim=28*28, units=500))model.add(Activation('relu'))model.add(Dense(units=500))model.add(Activation('relu'))model.add(Dense(units=10))model.add(Activation('softmax')) 1234# æ¨¡å‹é…ç½®model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) 1234# è®­ç»ƒmodel.fit(x_train, y_train, epochs=20, batch_size=100) Instructions for updating: Use tf.cast instead. Epoch 1/20 60000/60000 [==============================] - 5s 89us/step - loss: 0.2038 - acc: 0.9390 ... 60000/60000 [==============================] - 5s 86us/step - loss: 0.0051 - acc: 0.9985 Epoch 20/20 60000/60000 [==============================] - 5s 84us/step - loss: 0.0095 - acc: 0.9973 &lt;keras.callbacks.History at 0x103d9b710&gt; 1234# è®­ç»ƒè¯„åˆ†score = model.evaluate(x_train, y_train, batch_size=100)print('Total loss in training set:', score[0])print('Accuracy in training set:', score[1]) 60000/60000 [==============================] - 2s 26us/step Total loss in training set: 0.030331732142293125 Accuracy in training set: 0.9930500061313311 1234# æµ‹è¯•è¯„åˆ†score = model.evaluate(x_test, y_test, batch_size=100)print('Total loss in testing set:', score[0])print('Accuracy in testing set:', score[1]) 10000/10000 [==============================] - 0s 27us/step Total loss in testing set: 0.13895348183807527 Accuracy in testing set: 0.9754000073671341","link":"/2019/04/02/MNIST/"},{"title":"kaggleæ¯”èµ›åˆä½“éªŒ","text":"Hello,machine learning! kaggleé“¾æ¥ ğŸ‘‰ğŸ»è¯·ç‚¹æˆ‘ æ­¥éª¤æ•°æ®é¢„å¤„ç†ç”¨pandasè¯»å–è®­ç»ƒé›†train.csvæ–‡ä»¶ï¼Œå¹¶æŸ¥çœ‹è®­ç»ƒé›†ç»´åº¦è®­ç»ƒé›†å…±42000å¼ å›¾ç‰‡ï¼Œæ¯å¼ å›¾ç‰‡åƒç´ ä¸º28*281234import pandas as pdtrain = pd.read_csv('train.csv')train.shape (42000, 785) ç®€å•æŸ¥çœ‹æ•°æ®åå‘ç°ç¬¬ä¸€åˆ—ä¸ºlabelï¼Œåˆ†ç¦»å‡ºç¬¬ä¸€åˆ—ä¸ºtrain_labelå…¶ä½™ä¸ºtrain_dataï¼Œå¹¶å¯¹æ¯ä¸ªå›¾ç‰‡åšæ ‡å‡†åŒ–å¤„ç†123train_label = train.iloc[:,0:1]train_data = train.iloc[:,1:]train_data = train_data/255 å¯¼å…¥keras.utilsæ¨¡å—ä¸­çš„np_utilsï¼Œç›®çš„æ˜¯ä½¿åˆ†ç±»æ•°æ®å˜ä¸ºæ›´å®¹æ˜“å¤„ç†çš„å¸ƒå°”å€¼çŸ©é˜µæ•°æ®12from keras.utils import np_utilstrain_label = np_utils.to_categorical(train_label, 10) æ¨¡å‹æ­å»ºè¿™é‡Œé€‰æ‹©äº†ä½¿ç”¨äº†å…·æœ‰ä¸¤ä¸ªéšè—å±‚çš„ç¥ç»ç½‘ç»œï¼Œæ¯å±‚500ä¸ªç¥ç»å…ƒæ¿€æ´»å‡½æ•°ä¸ºReluï¼Œè¾“å‡ºå‡½æ•°ä¸ºsoftmax123456789101112131415from keras.datasets import mnistfrom keras.optimizers import Adamfrom keras.models import Sequentialfrom keras.layers import Dense, Activationmodel = Sequential()model.add(Dense(input_dim=28*28, units=500))model.add(Activation('relu'))model.add(Dense(units=500))model.add(Activation('relu'))model.add(Dense(units=500))model.add(Activation('relu'))model.add(Dense(units=10))model.add(Activation('softmax')) ä¼˜åŒ–é€‰æ‹©adamæ–¹æ³•ï¼Œä»£ä»·å‡½æ•°é‡‡ç”¨äº†åˆ†ç±»çš„äº¤å‰ç†µ123model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) å¼€å§‹è®­ç»ƒ123model.fit(train_data, train_label, epochs=20, batch_size=100) Epoch 1/20 42000/42000 [==============================] - 6s 142us/step - loss: 0.2332 - acc: 0.9297 Epoch 2/20 42000/42000 [==============================] - 6s 134us/step - loss: 0.0924 - acc: 0.9707 ... Epoch 20/20 42000/42000 [==============================] - 6s 139us/step - loss: 0.0124 - acc: 0.9966 æµ‹è¯•é›†æ­£ç¡®ç‡ä¸º99.66%123score = model.evaluate(train_data, train_label, batch_size=100)print('Total loss in training set:', score[0])print('Accuracy in training set:', score[1]) 42000/42000 [==============================] - 2s 38us/step Total loss in training set: 0.012173209706547606 Accuracy in training set: 0.9963333366882233 åˆ›å»ºé¢„æµ‹æ–‡ä»¶è¯»å–å¾…é¢„æµ‹æ–‡ä»¶test.csv1test = pd.read_csv('test.csv') å¼€å§‹é¢„æµ‹12predict = model.predict(test)predict = predict.tolist() å°†é¢„æµ‹ç»“æœè£…å…¥nparray12345678import numpy as nppre = np.array(np.zeros(28000)).reshape(28000,1).astype(np.int64)for i in range(28000): pre[i] = predict[i].index(max(predict[i]))index = np.array(np.arange(1,28001)).reshape(28000,1)result = np.hstack((index,pre)) å°†DataFrameå†™å…¥sample_submission.csvå¹¶ä¸Škaggleæäº¤1234pd_data = pd.DataFrame(result,columns=['ImageId','Label'])pd_data.set_index('ImageId', inplace=True)print(pd_data[:10])pd_data.to_csv('sample_submission.csv') å¤§æ¦‚é•¿ä¸‹é¢è¿™ä¸ªæ ·å­ ğŸ‘‡ğŸ» Label ImageId 1 2 2 0 3 9 4 0 5 3 6 7 7 0 8 3 9 0 10 3 æˆ‘çš„é¢„æµ‹å¾—åˆ†0.97700 å®Œç»“æ’’èŠ±ğŸ‰ğŸ‰ğŸ‰","link":"/2019/04/10/hello ML/"},{"title":"Matplotlibnç¬”è®°ğŸ“’","text":"12import matplotlib.pyplot as pltimport numpy as np 123x = np.linspace(1,10)y1 = 2*x + 1y2 = x**2 12345678910111213141516171819202122232425262728293031plt.figure(num = 3, figsize=(8,5))# x,yçš„æ ‡é¢˜plt.xlabel('$x$');plt.ylabel('$y$')plt.yticks([0,50,100], ['$bad$','$normal$','$good$'])# gca = get current axisax = plt.gca()ax.spines['right'].set_color('none')ax.spines['top'].set_color('none')ax.xaxis.set_ticks_position('bottom')ax.yaxis.set_ticks_position('left')# ax.spines['bottom'].set_position(('data',0))# ax.spines['left'].set_position(('data',0))l1, = plt.plot(x,y2,label = '$up$')l2, = plt.plot(x,y1,color='red',linewidth=1.0,linestyle='--',label='$down$')plt.legend(handles=[l1,l2],loc='best')# æ³¨è§£x0 = 6y0 = x0**2plt.scatter(x0,y0,s=20) # å±•ç¤ºç‚¹plt.plot([x0,x0],[y0,0],'k--',lw=1)plt.annotate(r'$2x+1=%s$' % y0,xy=(x0,y0),xycoords='data',xytext=(8,30), arrowprops=dict(arrowstyle='-&gt;',connectionstyle='arc3,rad=.2'),color='pink')plt.text(2,50,r'$This\\ is\\ some\\ text.\\ \\mu\\ \\sigma_i\\ \\alpha_t$',fontdict={'size':12,'color':'red'})plt.show() 1234def f(x,y): return (1-x/2+x**5+y**3)*np.exp(-x**2-y**2)def z(x,y): return (x**2 + y**2) 123456789101112n = 256x = np.linspace(-3,3,n)y = np.linspace(-3,3,n)X,Y = np.meshgrid(x,y)plt.contourf(X,Y,f(X,Y),7,alpha=0.5,cmap=plt.cm.cool)C = plt.contour(X,Y,f(X,Y),7,colors='black')plt.clabel(C,inline=True,)plt.xticks(())plt.yticks(())plt.show() 1234a = np.random.normal(0,1,100).reshape((10,10))plt.imshow(a,interpolation='nearest')plt.colorbar(shrink=0.9)plt.show &lt;function matplotlib.pyplot.show(*args, **kw)&gt; 1from mpl_toolkits.mplot3d import Axes3D 12345678910fig = plt.figure()ax = Axes3D(fig)X = np.arange(-4,4,0.25)Y = np.arange(-4,4,0.25)X,Y = np.meshgrid(X,Y)R = np.sqrt(X**2+Y**2)ax.plot_surface(X,Y,R,cmap='rainbow')ax.contourf(X,Y,R,zdir='z',offset=0,cmap='rainbow')plt.show() 12345678910plt.figure()plt.subplot(2,3,4)plt.plot(np.arange(1,100))plt.subplot(2,3,5)plt.plot(np.arange(1,20)**2)plt.subplot(2,1,1)plt.plot(np.random.normal(0,1,100))plt.subplot(2,3,6)plt.plot(np.array(np.sin(np.arange(0,10,0.1))))plt.show() 1import matplotlib.gridspec as gridspec 1234567891011# plt.figure()# ax1 = plt.subplot2grid((3,3),(0,0),colspan=3,rowspan=1)# ax1.plot(np.random.normal(0,1,100))# ax1.set_title('time')# ax2 = plt.subplot2grid((3,3),(1,0),colspan=2,rowspan=1)# ax2 = plt.subplot2grid((3,3),(1,2),colspan=1,rowspan=2)# ax2 = plt.subplot2grid((3,3),(2,0),colspan=1,rowspan=1)# ax2 = plt.subplot2grid((3,3),(2,1),colspan=1,rowspan=1)# plt.show() 1234567# plt.figure()# gs = gridspec.GridSpec(3,3)# ax1 = plt.subplot(gs[0,:])# ax2 = plt.subplot(gs[1,:2])# ax3 = plt.subplot(gs[1:,2])# ax4 = plt.subplot(gs[-1,0])# ax5 = plt.subplot(gs[-1,1]) 123456789101112x = np.arange(0,50)y1 = np.random.normal(0,1,50)y2 = np.random.normal(1,2,50)fig,ax1 = plt.subplots()ax2 = ax1.twinx()ax1.plot(x,y1,'g-')ax2.plot(x,-y2,'b-')ax1.set_xlabel('X data')ax1.set_ylabel('Y1',color='g')ax2.set_ylabel('Y2',color='b')plt.show() 1from scipy.stats import t 12345x = np.arange(-5,5,0.1)plt.figure()plt.plot(x,t.pdf(x,2))plt.plot(x,t.pdf(x,10))plt.show() 12","link":"/2019/03/26/matplotlib/"},{"title":"Numpyç¬”è®°ğŸ“’","text":"NumPy(Numerical Python) æ˜¯ Python è¯­è¨€çš„ä¸€ä¸ªæ‰©å±•ç¨‹åºåº“ï¼Œæ”¯æŒå¤§é‡çš„ç»´åº¦æ•°ç»„ä¸çŸ©é˜µè¿ç®—ï¼Œæ­¤å¤–ä¹Ÿé’ˆå¯¹æ•°ç»„è¿ç®—æä¾›å¤§é‡çš„æ•°å­¦å‡½æ•°åº“ã€‚123456import numpy as npl = [[1,2,3],[2,3,4]]# åˆ—è¡¨è½¬åŒ–æˆçŸ©é˜µarray = np.array(l)print(array) [[1 2 3] [2 3 4]] numpyçš„å‡ ç§å±æ€§123456# ç»´åº¦print('number of dim:',array.ndim)# è¡Œæ•°å’Œåˆ—æ•°print('shape :',array.shape) # å…ƒç´ ä¸ªæ•°print('size:',array.size) number of dim: 2 shape : (2, 3) size: 6 åˆ›å»ºarray12a = np.array([2,3,4],dtype = np.int)print(a,a.dtype) [2 3 4] int64 123# åˆ›å»ºå…¨0æ•°ç»„a = np.zeros((3,4),dtype = np.int16)print(a) [[0 0 0 0] [0 0 0 0] [0 0 0 0]] 123# åˆ›å»ºå…¨1æ•°ç»„a = np.ones((3,4),dtype = np.int64)print(a) [[1 1 1 1] [1 1 1 1] [1 1 1 1]] 123# åˆ›å»ºå…¨ç©ºæ•°ç»„a = np.empty((3,4),dtype = np.float)print(a) [[-1.49166815e-154 -1.49166815e-154 4.27255699e+180 6.12033286e+257] [ 3.83819517e+151 9.77368093e+165 1.03927302e-042 5.24049485e+174] [ 4.27796595e-033 5.81088333e+294 -1.49166815e-154 8.38743761e-309]] 123# åˆ›å»ºè¿ç»­æ•°ç»„a = np.arange(1,13).reshape(3,4)print(a) [[ 1 2 3 4] [ 5 6 7 8] [ 9 10 11 12]] 123# ç”Ÿæˆçº¿æ®µa = np.linspace(1,10,6).reshape(2,3)print(a) [[ 1. 2.8 4.6] [ 6.4 8.2 10. ]] åŸºç¡€è¿ç®—åŸºæœ¬è¿ç®—1æ•°ç»„è¿ç®—12a = np.array([10,20,30,40])b = np.arange(4) 1a-b array([10, 19, 28, 37]) 1b**2 array([0, 1, 4, 9]) 1np.sin(a) array([-0.54402111, 0.91294525, -0.98803162, 0.74511316]) 1b&lt;3 array([ True, True, True, False]) çŸ©é˜µè¿ç®—1234a = np.array([[1,2],[3,4]])b = np.arange(4).reshape(2,2)print(a)print(b) [[1 2] [3 4]] [[0 1] [2 3]] 1234# å¯¹åº”å…ƒç´ ç›¸ä¹˜print(a*b)# çŸ©é˜µä¹˜æ³•print(np.dot(a,b)) [[ 0 2] [ 6 12]] [[ 4 7] [ 8 15]] 123456a = np.random.random((2,4))print(a)# axis=1æ—¶æ¯è¡Œåˆ†åˆ«è®¡ç®—ï¼Œaxis=0æ—¶æ¯åˆ—åˆ†åˆ«è®¡ç®—print('sum =',np.sum(a,axis=1))print('min =',np.min(a,axis=0))print('max =',np.max(a)) [[0.31357817 0.09926399 0.57284534 0.9692283 ] [0.86206853 0.94729865 0.80886452 0.01849844]] sum = [1.9549158 2.63673014] min = [0.31357817 0.09926399 0.57284534 0.01849844] max = 0.9692282997410551 åŸºæœ¬è¿ç®—212A = np.arange(2,14).reshape(3,4)print(A) [[ 2 3 4 5] [ 6 7 8 9] [10 11 12 13]] 12# æœ€å°ï¼ˆå¤§ï¼‰å€¼ç´¢å¼•A.argmax() 11 1234# å¹³å‡å€¼print(A.mean())# å¯¹åˆ—æ±‚å¹³å‡print(A.mean(axis=0)) 7.5 [6. 7. 8. 9.] 12# ä¸­ä½æ•°np.median(A) 7.5 12# ç´¯åŠ print(np.cumsum(A)) [ 2 5 9 14 20 27 35 44 54 65 77 90] 12# ç´¯å·®print(np.diff(A)) [[1 1 1] [1 1 1] [1 1 1]] 12# æ’åºprint(np.sort(A)) [[ 2 3 4 5] [ 6 7 8 9] [10 11 12 13]] 12# è½¬ç½®print(np.transpose(A)) [[ 2 6 10] [ 3 7 11] [ 4 8 12] [ 5 9 13]] 12# A*ATprint(np.dot(A,A.T)) [[ 54 110 166] [110 230 350] [166 350 534]] 12# æ»¤æ³¢print(np.clip(A,5,9)) [[5 5 5 5] [6 7 8 9] [9 9 9 9]] 12# é“ºå¹³print(A.flatten()) [ 2 3 4 5 6 7 8 9 10 11 12 13] numpyç´¢å¼•12A = np.arange(3,15).reshape(3,4)print(A) [[ 3 4 5 6] [ 7 8 9 10] [11 12 13 14]] 12A[1,1]#A[1][1] 8 arrayåˆå¹¶1234A = np.array([1,1,1])B = np.array([2,2,2])np.vstack((A,B)) array([[1, 1, 1], [2, 2, 2]]) 1np.hstack((A,B)) array([1, 1, 1, 2, 2, 2]) arrayåˆ†å‰²12A = np.arange(12).reshape(3,4)print(A) [[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11]] 12345np.split(A,3)# æ¨ªå‘åˆ†å‰²# np.vsplit(A,3)# çºµå‘åˆ†å‰²# np.hsplit(A,2) [array([[0, 1, 2, 3]]), array([[4, 5, 6, 7]]), array([[ 8, 9, 10, 11]])] 12# ä¸ç­‰é‡åˆ†å‰²np.array_split(A,3,axis=1) [array([[0, 1], [4, 5], [8, 9]]), array([[ 2], [ 6], [10]]), array([[ 3], [ 7], [11]])] copy123a = np.array([1,2])# b.copy()æ²¡æœ‰å…³è”æ€§ï¼Œä¸ºæµ…æ‹·è´a is b.copy() False","link":"/2019/03/02/numpy/"},{"title":"scrapyå…¥é—¨","text":"å®‰è£…1$ pip3 install scrapy åˆ›å»ºé¡¹ç›®12$ cd desktop/tutorial$ scrapy startproject tutorial åˆ›å»ºçˆ¬è™«123456789101112131415161718192021# åœ¨tutorial/spidersç›®å½•ä¸‹åˆ›å»ºquotes_spider.pyå†™å…¥ï¼šimport scrapyclass QuotesSpider(scrapy.Spider): name = \"quotes\" def start_requests(self): urls = [ 'http://quotes.toscrape.com/page/1/', 'http://quotes.toscrape.com/page/2/', ] for url in urls: yield scrapy.Request(url=url, callback=self.parse) def parse(self, response): page = response.url.split(\"/\")[-2] filename = 'quotes-%s.html' % page with open(filename, 'wb') as f: f.write(response.body) self.log('Saved file %s' % filename) è¿è¡Œçˆ¬è™«1$ scrapy crawl quotes å°è¯•ä½¿ç”¨shellè°ƒè¯•1$ scrapy shell &apos;http://quotes.toscrape.com/page/1/&apos; 123# å¯ä½¿ç”¨csså’Œxpathè¿›è¡ŒåŒ¹é…&gt;&gt;&gt; response.css('title::text').extract_first()'Quotes to Scrape'","link":"/2019/01/08/scrapyå…¥é—¨/"},{"title":"ç¡¬trainçš„æ•…äº‹","text":"Thanks a lot, machine learning! Joel GrusFizz Buzz in Tensorflow","link":"/2019/03/30/video/"},{"title":"ä¸€é“æ’åºé¢˜","text":"ç»™å®šä¸€ç»„æ•°ï¼Œæ¯æ¬¡åªèƒ½äº¤æ¢ä¸¤ä¸ªæ•°å­—çš„ä½ç½®ï¼Œæ±‚å…¨éƒ¨æ’åºå®Œæˆçš„æœ€å°äº¤æ¢æ¬¡æ•° 12345678910111213141516def s(l): k = 0 for i in range(len(l)): li = l[i:] j = li.index(min(li)) if j == 0: continue l[i], l[i+j] = l[i+j], l[i] k += 1 return kl = [5,4,3,2,1]print(s(l))# &gt;&gt;&gt; 2","link":"/2019/03/30/ä¸€é“æ’åºé¢˜/"},{"title":"Multithreading","text":"å¤šçº¿ç¨‹GIL(Global Interpreter Lock)å°½ç®¡Pythonå®Œå…¨æ”¯æŒå¤šçº¿ç¨‹ç¼–ç¨‹ï¼Œ ä½†æ˜¯è§£é‡Šå™¨çš„Cè¯­è¨€å®ç°éƒ¨åˆ†åœ¨å®Œå…¨å¹¶è¡Œæ‰§è¡Œæ—¶å¹¶ä¸æ˜¯çº¿ç¨‹å®‰å…¨çš„ã€‚ å®é™…ä¸Šï¼Œè§£é‡Šå™¨è¢«ä¸€ä¸ªå…¨å±€è§£é‡Šå™¨é”ä¿æŠ¤ç€ï¼Œå®ƒç¡®ä¿ä»»ä½•æ—¶å€™éƒ½åªæœ‰ä¸€ä¸ªPythonçº¿ç¨‹æ‰§è¡Œã€‚ GILæœ€å¤§çš„é—®é¢˜å°±æ˜¯Pythonçš„å¤šçº¿ç¨‹ç¨‹åºå¹¶ä¸èƒ½åˆ©ç”¨å¤šæ ¸CPUçš„ä¼˜åŠ¿ ï¼ˆæ¯”å¦‚ä¸€ä¸ªä½¿ç”¨äº†å¤šä¸ªçº¿ç¨‹çš„è®¡ç®—å¯†é›†å‹ç¨‹åºåªä¼šåœ¨ä¸€ä¸ªå•CPUä¸Šé¢è¿è¡Œï¼‰ã€‚ æ·»åŠ çº¿ç¨‹12345678import threading# è·å–å·²æ¿€æ´»çš„çº¿ç¨‹æ•°threading.active_count()# æŸ¥çœ‹æ‰€æœ‰çº¿ç¨‹ä¿¡æ¯threading.enumerate()# æŸ¥çœ‹ç°åœ¨æ­£åœ¨è¿è¡Œçš„çº¿ç¨‹threading.current_thread() æ·»åŠ çº¿ç¨‹1234567891011def thread_job(): print('This is a thread of %s' % threading.current_thread())def main(): # å®šä¹‰çº¿ç¨‹ thread = threading.Thread(target = thread_job) # è®©çº¿ç¨‹å¼€å§‹å·¥ä½œ thread.start()if __name__ == '__main__': main() joinæ‰€æœ‰çº¿ç¨‹è¿è¡Œç»“æŸåå†æ‰§è¡Œä¸»çº¿ç¨‹ å‚¨å­˜çº¿ç¨‹ç»“æœåˆ°Queue1234567891011121314151617181920212223242526272829import threadingfrom queue import Queuedef job(l, q): for i in range(len(l)): l[i] = l[i] ** 2 q.put(l)def multithreading(): q = Queue() data = [[1, 2, 3], [3, 4, 5]] threads = [] for i in range(len(data)): t = threading.Thread(target=job, args=(data[i], q)) threads.append(t) t.start() for thread in threads: thread.join() result = [] for _ in range(len(data)): result.append(q.get()) print(result)if __name__ == '__main__': multithreading()## [[1, 4, 9], [9, 16, 25]] GILæµ‹è¯•æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª job, åˆ†åˆ«ç”¨ threading å’Œ ä¸€èˆ¬çš„æ–¹å¼æ‰§è¡Œè¿™æ®µç¨‹åº. å¹¶ä¸”åˆ›å»ºä¸€ä¸ª list æ¥å­˜æ”¾æˆ‘ä»¬è¦å¤„ç†çš„æ•°æ®. åœ¨ Normal çš„æ—¶å€™, æˆ‘ä»¬è¿™ä¸ª list æ‰©å±•4å€, åœ¨ threading çš„æ—¶å€™, æˆ‘ä»¬å»ºç«‹4ä¸ªçº¿ç¨‹, å¹¶å¯¹è¿è¡Œæ—¶é—´è¿›è¡Œå¯¹æ¯”.123456789101112131415161718192021222324252627282930313233343536373839import timeimport threadingfrom queue import Queueimport copydef job(l,q): res = sum(l) q.put(res)def multithreading(l): q = Queue() threads = [] for i in range(4): t = threading.Thread(target=job, args=(copy.copy(l),q)) t.start() threads.append(t) for thread in threads: thread.join() total = 0 for _ in range(4): total += q.get() print(total)def normal(l): res = sum(l*4) print(res)if __name__ == '__main__': l = list(range(1000000)) s_t = time.time() multithreading(l) print('multithreading: %ss' %(time.time()-s_t)) s_t = time.time() normal(l) print('normal: %ss' %(time.time()-s_t))## 1999998000000## multithreading: 0.06084728240966797s## 1999998000000## normal: 0.05951380729675293s çº¿ç¨‹é”ğŸ”’12345lock = threading.Lock()# locklock.acquire()# releaselock.release()","link":"/2019/02/25/å¤šçº¿ç¨‹/"},{"title":"Multiprocessing","text":"å¤šè¿›ç¨‹åˆ›å»ºè¿›ç¨‹1import multiprocessing as mp 1234567def job(): print('This is a process')if __name__ == '__main__': p1 = mp.Process(target = job) p1.start() p1.join() æŠŠç»“æœæ”¾åœ¨Queueä¸­ï¼Œå‚è€ƒå¤šçº¿ç¨‹12# ä¸åŒç‚¹q = mp.Queue() è¿›ç¨‹æ± poolè¿›ç¨‹æ± å°±æ˜¯æˆ‘ä»¬å°†æ‰€è¦è¿è¡Œçš„ä¸œè¥¿ï¼Œæ”¾åˆ°æ± å­é‡Œï¼ŒPythonä¼šè‡ªè¡Œè§£å†³å¤šè¿›ç¨‹çš„é—®é¢˜ã€‚1234567891011121314# å®šä¹‰ä¸€ä¸ªJOBdef job(x): return x*x# æ¥ä¸‹æ¥ç”¨map()è·å–ç»“æœï¼Œåœ¨map()ä¸­éœ€è¦æ”¾å…¥å‡½æ•°å’Œéœ€è¦è¿­ä»£è¿ç®—çš„å€¼ï¼Œç„¶åå®ƒä¼šè‡ªåŠ¨åˆ†é…ç»™CPUæ ¸ï¼Œè¿”å›ç»“æœdef multicore(): # å®šä¹‰ä¸€ä¸ªPOOLï¼Œå¯ä»¥è‡ªå®šä¹‰éœ€è¦çš„æ ¸çš„æ•°é‡ # processes=3 pool = mp.Pool() res = pool.map(job, range(10)) print(res) if __name__ == '__main__': multicore()## [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] å…±äº«å†…å­˜åªæœ‰ç”¨å…±äº«å†…å­˜æ‰èƒ½è®©CPUä¹‹é—´æœ‰äº¤æµã€‚123# å…¶ä¸­då’Œiå‚æ•°ç”¨æ¥è®¾ç½®æ•°æ®ç±»å‹çš„ï¼Œdè¡¨ç¤ºä¸€ä¸ªåŒç²¾æµ®ç‚¹ç±»å‹ï¼Œiè¡¨ç¤ºä¸€ä¸ªå¸¦ç¬¦å·çš„æ•´å‹ã€‚value1 = mp.Value('i', 0) value2 = mp.Value('d', 3.14) è¿›ç¨‹é”ğŸ”’å‚è€ƒå¤šçº¿ç¨‹","link":"/2019/02/26/å¤šè¿›ç¨‹/"},{"title":"æ­£åˆ™è¡¨è¾¾å¼","text":"RegEx 123456import re# []ä¸­ä¸ºå¯ä»¥çš„å­—ç¬¦print(re.search(r\"r[a-z]n\", 'dog runs to cat'))print(re.search(r\"r[0-9]n\", 'dog r4ns to cat'))print(re.search(r\"r[a-z0-9]n\", 'dog runs to cat')) &lt;_sre.SRE_Match object; span=(4, 7), match=&apos;run&apos;&gt; &lt;_sre.SRE_Match object; span=(4, 7), match=&apos;r4n&apos;&gt; &lt;_sre.SRE_Match object; span=(4, 7), match=&apos;run&apos;&gt; ç‰¹æ®Šç§ç±»åŒ¹é…æ•°å­—1234# \\d ä»£è¡¨æ‰€æœ‰æ•°å­—print(re.search(r\"r\\dn\", 'dog r3ns to cat'))# \\D ä»£è¡¨æ‰€æœ‰ä¸æ˜¯æ•°å­—print(re.search(r\"r\\Dn\", 'dog runs to cat')) &lt;_sre.SRE_Match object; span=(4, 7), match=&apos;r3n&apos;&gt; &lt;_sre.SRE_Match object; span=(4, 7), match=&apos;run&apos;&gt; ç©ºç™½1234# \\s åŒ¹é…æ‰€æœ‰ç©ºç™½ç¬¦å·[\\t\\n\\r\\f\\v]print(re.search(r\"r\\sn\", 'dog r\\nns to cat'))# \\S åŒ¹é…ä¸æ˜¯ç©ºç™½ç¬¦å·print(re.search(r\"r\\Sn\", 'dog runs to cat')) &lt;_sre.SRE_Match object; span=(4, 7), match=&apos;r\\nn&apos;&gt; &lt;_sre.SRE_Match object; span=(4, 7), match=&apos;run&apos;&gt; æ‰€æœ‰å­—æ¯æ•°å­—å’Œâ€_â€1234# \\w : [0-9a-zA-Z_]print(re.search(r\"r\\wn\", 'dog runs to cat'))# \\W opposite to \\wprint(re.search(r\"r\\Wn\", 'dog runs to cat')) &lt;_sre.SRE_Match object; span=(4, 7), match=&apos;run&apos;&gt; None ç©ºæ ¼1234# \\b ç´§è´´ç€å­—ç¬¦çš„ç©ºç™½å­—ç¬¦print(re.search(r\"\\bruns\\b\", 'dog runs to cat'))# \\B æ— éœ€ç´§è´´ç€print(re.search(r\"\\B runs \\B\", 'dog runs to cat')) &lt;_sre.SRE_Match object; span=(4, 8), match=&apos;runs&apos;&gt; &lt;_sre.SRE_Match object; span=(4, 10), match=&apos; runs &apos;&gt; ç‰¹æ®Šå­—ç¬¦å’Œä»»æ„å­—ç¬¦1234# \\\\print(re.search(r\"runs\\\\\", 'dog runs\\ to cat'))# . é™¤äº†\\néƒ½å¯ä»¥åŒ¹é…print(re.search(r\"r.ns\", 'dog r[ns to cat')) &lt;_sre.SRE_Match object; span=(4, 9), match=&apos;runs\\\\&apos;&gt; &lt;_sre.SRE_Match object; span=(4, 8), match=&apos;r[ns&apos;&gt; å¥é¦–å¥å°¾1234# ^ å¥é¦–print(re.search(r\"^dog\", 'dog runs to cat'))# $ å¥å°¾print(re.search(r\"cat$\", 'dog runs to cat')) &lt;_sre.SRE_Match object; span=(0, 3), match=&apos;dog&apos;&gt; &lt;_sre.SRE_Match object; span=(12, 15), match=&apos;cat&apos;&gt; æ˜¯å¦123# ï¼Ÿprint(re.search(r\"Mon(day)?\", 'Monday'))print(re.search(r\"Mon(day)?\", 'Mon')) &lt;_sre.SRE_Match object; span=(0, 6), match=&apos;Monday&apos;&gt; &lt;_sre.SRE_Match object; span=(0, 3), match=&apos;Mon&apos;&gt; å¤šè¡ŒåŒ¹é…123456# multi-linestring = '''Dog runs to cat.I run to dog.'''print(re.search(r\"^I\", string, flags=re.M)) &lt;_sre.SRE_Match object; span=(18, 19), match=&apos;I&apos;&gt; 0æˆ–å¤šæ¬¡ 1æˆ–å¤šæ¬¡1234567# * 0æˆ–å¤šæ¬¡print(re.search(r\"ab*\", \"a\"))print(re.search(r\"ab*\", \"abbbbbbb\"))# + 1æˆ–å¤šæ¬¡print(re.search(r\"ab+\", \"a\"))print(re.search(r\"ab+\", \"abbbbbbb\")) &lt;_sre.SRE_Match object; span=(0, 1), match=&apos;a&apos;&gt; &lt;_sre.SRE_Match object; span=(0, 8), match=&apos;abbbbbbb&apos;&gt; None &lt;_sre.SRE_Match object; span=(0, 8), match=&apos;abbbbbbb&apos;&gt; å¯é€‰æ¬¡æ•°1234# {m,n} å¯é€‰æ¬¡æ•°print(re.search(r\"ab{2,10}\", \"a\"))print(re.search(r\"ab{2,7}\", \"abbbbbb\"))print(re.search(r\"ab{6}\", \"abbbbbb\")) None &lt;_sre.SRE_Match object; span=(0, 7), match=&apos;abbbbbb&apos;&gt; &lt;_sre.SRE_Match object; span=(0, 7), match=&apos;abbbbbb&apos;&gt; GROUPç»„12345678910# groupmatch = re.search(r\"(\\d+), Data: (.+)\", \"ID: 123456 Data: Jan/8/2019\")# print(match.group())# print(match.group(1))# print(match.group(2))# è‡ªå®šä¹‰ç»„åmatch = re.search(r\"(?P&lt;id&gt;\\d+), Data: (?P&lt;data&gt;.+)\", \"ID: 123456 Data: Jan/8/2019\")# print(match.group(id))# print(match.group(data)) å¯»æ‰¾æ‰€æœ‰åŒ¹é…12345# findallprint(re.findall(r\"r.n\", \"ran run ren\"))# | : orprint(re.findall(r\"(ran|run)\", \"ran run ren\")) [&apos;ran&apos;, &apos;run&apos;, &apos;ren&apos;] [&apos;ran&apos;, &apos;run&apos;] æ›¿æ¢12# re.sub æ›¿æ¢print(re.sub(r\"r[ua]ns\", \"catches\", \"Dog runs to cat.\")) Dog catches to cat. åˆ†è£‚12# re.splitprint(re.split(r\"[;,\\.]\", \"a;b,c.d;e\")) [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;] Compile123# Compilecompile_re = re.compile(r\"r[au]ns\")print(compile_re.search(\"Dog runs to cat.\")) &lt;_sre.SRE_Match object; span=(4, 8), match=&apos;runs&apos;&gt;","link":"/2019/01/08/æ­£åˆ™è¡¨è¾¾å¼/"},{"title":"ç•™è¨€æ¿ ğŸ“®","text":"æ¬¢è¿ç•™ä¸‹è¯„è®ºï½","link":"/2000/03/02/ç•™è¨€æ¿/"},{"title":"Kerasæ‰‹æŠŠæ‰‹æ•™å­¦ä¹‹ ğŸ’¯","text":"Keras Sequential é¡ºåºæ¨¡å‹ æ¨¡å‹æ­å»ºç›´æ¥çœ‹ä¾‹å­ç‚¹è¿™é‡Œ ğŸ‘ˆğŸ» Sequential æ¨¡å‹æ˜¯å±‚çš„çº¿æ€§å †æ ˆ 12345678910111213141516import kerasfrom keras.models import Sequentialfrom keras.layers import Dense, Activationmodel = Sequential()# Dense: fully connection(DNNå¯†é›†å‹ç¥ç»ç½‘ç»œ)model.add(Dense(input_dim=28*28,units=500))# activation function:# softplus, softsign, relu, tanh, hard_sigmoid, linearmodel.add(Activation('sigmoid'))# the second hidden layermodel.add(Dense(units=500))model.add(Activation('sigmoid'))model.add(Dense(units=10))model.add(Activation('softmax')) æ¨¡å‹é…ç½®åœ¨è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œæ‚¨éœ€è¦é…ç½®å­¦ä¹ è¿‡ç¨‹ï¼Œè¿™æ˜¯é€šè¿‡ compile æ–¹æ³•å®Œæˆçš„ã€‚å®ƒæ¥æ”¶ä¸‰ä¸ªå‚æ•°ï¼š ä¼˜åŒ–å™¨ optimizerã€‚å®ƒå¯ä»¥æ˜¯ç°æœ‰ä¼˜åŒ–å™¨çš„å­—ç¬¦ä¸²æ ‡è¯†ç¬¦ï¼Œå¦‚ rmsprop æˆ– adagradï¼Œä¹Ÿå¯ä»¥æ˜¯ Optimizer ç±»çš„å®ä¾‹ã€‚ æŸå¤±å‡½æ•° lossï¼Œæ¨¡å‹è¯•å›¾æœ€å°åŒ–çš„ç›®æ ‡å‡½æ•°ã€‚å®ƒå¯ä»¥æ˜¯ç°æœ‰æŸå¤±å‡½æ•°çš„å­—ç¬¦ä¸²æ ‡è¯†ç¬¦ï¼Œå¦‚ categorical_crossentropy æˆ– mseï¼Œä¹Ÿå¯ä»¥æ˜¯ä¸€ä¸ªç›®æ ‡å‡½æ•°ã€‚ è¯„ä¼°æ ‡å‡† metricsã€‚å¯¹äºä»»ä½•åˆ†ç±»é—®é¢˜ï¼Œä½ éƒ½å¸Œæœ›å°†å…¶è®¾ç½®ä¸º metrics = ['accuracy']ã€‚ 123456789101112131415161718# äºŒåˆ†ç±»é—®é¢˜model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])# å‡æ–¹è¯¯å·®å›å½’é—®é¢˜model.compile(optimizer='rmsprop', loss='mse')# è‡ªå®šä¹‰è¯„ä¼°æ ‡å‡†å‡½æ•°import keras.backend as Kdef mean_pred(y_true, y_pred): return K.mean(y_pred)model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy', mean_pred]) 123456# step 3.1:# Configuration# optimizer = [SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam]model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) æ¨¡å‹è®­ç»ƒKeras æ¨¡å‹åœ¨è¾“å…¥æ•°æ®å’Œæ ‡ç­¾çš„ Numpy çŸ©é˜µä¸Šè¿›è¡Œè®­ç»ƒã€‚ä¸ºäº†è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œä½ é€šå¸¸ä¼šä½¿ç”¨ fit å‡½æ•°ã€‚ 1234567# å…·æœ‰ 10 ä¸ªç±»çš„å•è¾“å…¥æ¨¡å‹ï¼ˆå¤šåˆ†ç±»åˆ†ç±»ï¼‰ï¼š# ç”Ÿæˆè™šæ‹Ÿæ•°æ®import numpy as npdata = np.random.random((50000, 28*28))labels = np.random.randint(10, size=(50000, 1))# å°†æ ‡ç­¾è½¬æ¢ä¸ºåˆ†ç±»çš„ one-hot ç¼–ç one_hot_labels = keras.utils.to_categorical(labels, num_classes=10) 1234567891011# step 3.2:# Find the optimal network parameters# do not really minimize total loss# betch_size:# --&gt; pick the 1st batch L' = L1 + L31 + ...# update parameters once# --&gt; pick the 2nd batch ...# all of the betch make one epoch: need 20 epoch# when beach_size = 1:# Stochastic gradient descentmodel.fit(data, one_hot_labels, epochs=20, batch_size=100) Epoch 1/20 50000/50000 [==============================] - 4s 84us/step - loss: 2.3052 - acc: 0.1004 Epoch 2/20 50000/50000 [==============================] - 5s 92us/step - loss: 2.3046 - acc: 0.1019 Epoch 3/20 50000/50000 [==============================] - 4s 87us/step - loss: 2.3053 - acc: 0.0997 Epoch 4/20 50000/50000 [==============================] - 4s 84us/step - loss: 2.3057 - acc: 0.1014 Epoch 5/20 50000/50000 [==============================] - 5s 92us/step - loss: 2.3057 - acc: 0.1027 Epoch 6/20 50000/50000 [==============================] - 5s 91us/step - loss: 2.3065 - acc: 0.1035 Epoch 7/20 50000/50000 [==============================] - 4s 84us/step - loss: 2.3077 - acc: 0.1034 Epoch 8/20 50000/50000 [==============================] - 5s 94us/step - loss: 2.3081 - acc: 0.1039 Epoch 9/20 50000/50000 [==============================] - 4s 89us/step - loss: 2.3057 - acc: 0.1109 Epoch 10/20 50000/50000 [==============================] - 4s 87us/step - loss: 2.3012 - acc: 0.1190 Epoch 11/20 50000/50000 [==============================] - 4s 87us/step - loss: 2.2925 - acc: 0.1285 Epoch 12/20 50000/50000 [==============================] - 4s 88us/step - loss: 2.2836 - acc: 0.1375 Epoch 13/20 50000/50000 [==============================] - 4s 84us/step - loss: 2.2744 - acc: 0.1476 Epoch 14/20 50000/50000 [==============================] - 4s 86us/step - loss: 2.2675 - acc: 0.1526 Epoch 15/20 50000/50000 [==============================] - 4s 85us/step - loss: 2.2638 - acc: 0.1551 Epoch 16/20 50000/50000 [==============================] - 4s 80us/step - loss: 2.2556 - acc: 0.1602 Epoch 17/20 50000/50000 [==============================] - 4s 83us/step - loss: 2.2525 - acc: 0.1638 Epoch 18/20 50000/50000 [==============================] - 5s 94us/step - loss: 2.2534 - acc: 0.1617 Epoch 19/20 50000/50000 [==============================] - 5s 93us/step - loss: 2.2462 - acc: 0.1681 Epoch 20/20 50000/50000 [==============================] - 4s 83us/step - loss: 2.2403 - acc: 0.1694 &lt;keras.callbacks.History at 0x126444278&gt; ExampleåŸºäºå¤šå±‚æ„ŸçŸ¥å™¨ (MLP) çš„ softmax å¤šåˆ†ç±»ï¼ˆåˆ†ç±»å™¨ï¼‰ï¼š 123456789101112131415import kerasfrom keras.models import Sequentialfrom keras.layers import Dense, Dropout, Activationfrom keras.optimizers import SGD# ç”Ÿæˆè™šæ‹Ÿæ•°æ®import numpy as np# 1000è¡Œ*20åˆ— çš„åŒºé—´åœ¨[0.,1.)çš„æµ®ç‚¹æ•°x_train = np.random.random((1000, 20))# ç”Ÿæˆ 1000è¡Œ*1åˆ— çš„åŒºé—´åœ¨[0-10)çš„æ•´æ•°ï¼Œéšåè½¬åŒ–ä¸ºåˆ†ç±»çš„ one-hot ç¼–ç ï¼ˆ1000è¡Œ*10åˆ— çš„(0,1)çŸ©é˜µï¼‰y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)# 100è¡Œ*20åˆ— çš„æµ‹è¯•é›†x_test = np.random.random((100, 20))# 100è¡Œ*10åˆ— çš„æµ‹è¯•æ ‡ç­¾y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10) 123456789model = Sequential()# Dense(64) æ˜¯ä¸€ä¸ªå…·æœ‰ 64 ä¸ªéšè—ç¥ç»å…ƒçš„å…¨è¿æ¥å±‚ã€‚# åœ¨ç¬¬ä¸€å±‚å¿…é¡»æŒ‡å®šæ‰€æœŸæœ›çš„è¾“å…¥æ•°æ®å°ºå¯¸ï¼š# åœ¨è¿™é‡Œï¼Œæ˜¯ä¸€ä¸ª 20 ç»´çš„å‘é‡ã€‚model.add(Dense(units=64, activation='relu', input_dim=20))model.add(Dropout(rate=0.5))model.add(Dense(units=64, activation='relu'))model.add(Dropout(rate=0.5))model.add(Dense(units=10, activation='softmax')) 123456# ä¼˜åŒ–å™¨sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)# æ¨¡å‹é…ç½®model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy']) 1234# æ¨¡å‹è®­ç»ƒmodel.fit(x_train, y_train, epochs=20, batch_size=128) Epoch 1/20 1000/1000 [==============================] - 0s 402us/step - loss: 2.4034 - acc: 0.1010 Epoch 2/20 1000/1000 [==============================] - 0s 19us/step - loss: 2.3808 - acc: 0.0920 Epoch 3/20 1000/1000 [==============================] - 0s 22us/step - loss: 2.3396 - acc: 0.1120 Epoch 4/20 1000/1000 [==============================] - 0s 23us/step - loss: 2.3249 - acc: 0.1190 Epoch 5/20 1000/1000 [==============================] - 0s 20us/step - loss: 2.3356 - acc: 0.0980 Epoch 6/20 1000/1000 [==============================] - 0s 22us/step - loss: 2.3233 - acc: 0.1210 Epoch 7/20 1000/1000 [==============================] - 0s 18us/step - loss: 2.3070 - acc: 0.1080 Epoch 8/20 1000/1000 [==============================] - 0s 22us/step - loss: 2.3190 - acc: 0.1030 Epoch 9/20 1000/1000 [==============================] - 0s 22us/step - loss: 2.3112 - acc: 0.0900 Epoch 10/20 1000/1000 [==============================] - 0s 20us/step - loss: 2.3076 - acc: 0.0960 Epoch 11/20 1000/1000 [==============================] - 0s 15us/step - loss: 2.3067 - acc: 0.1060 Epoch 12/20 1000/1000 [==============================] - 0s 16us/step - loss: 2.3058 - acc: 0.1160 Epoch 13/20 1000/1000 [==============================] - 0s 16us/step - loss: 2.2988 - acc: 0.1180 Epoch 14/20 1000/1000 [==============================] - 0s 17us/step - loss: 2.3008 - acc: 0.1240 Epoch 15/20 1000/1000 [==============================] - 0s 20us/step - loss: 2.3036 - acc: 0.1090 Epoch 16/20 1000/1000 [==============================] - 0s 22us/step - loss: 2.3042 - acc: 0.1060 Epoch 17/20 1000/1000 [==============================] - 0s 18us/step - loss: 2.3016 - acc: 0.1070 Epoch 18/20 1000/1000 [==============================] - 0s 25us/step - loss: 2.3054 - acc: 0.1390 Epoch 19/20 1000/1000 [==============================] - 0s 39us/step - loss: 2.2960 - acc: 0.1200 Epoch 20/20 1000/1000 [==============================] - 0s 34us/step - loss: 2.3021 - acc: 0.0940 &lt;keras.callbacks.History at 0x1842de6b38&gt; 12# æ¨¡å‹è¯„åˆ†score = model.evaluate(x_test, y_test, batch_size=128) 100/100 [==============================] - 0s 13us/step","link":"/2019/03/27/keras notebook/"},{"title":"SQL","text":"SQL SQL æŒ‡ç»“æ„åŒ–æŸ¥è¯¢è¯­è¨€ SQL ä½¿æˆ‘ä»¬æœ‰èƒ½åŠ›è®¿é—®æ•°æ®åº“ SQL æ˜¯ä¸€ç§ ANSI çš„æ ‡å‡†è®¡ç®—æœºè¯­è¨€ RDBMS - å…³ç³»æ•°æ®åº“ç®¡ç†ç³»ç»Ÿï¼ˆRelational Database Management Systemï¼‰ DML å’Œ DDLå¯ä»¥æŠŠ SQL åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼šæ•°æ®æ“ä½œè¯­è¨€ (DML) å’Œ æ•°æ®å®šä¹‰è¯­è¨€ (DDL)ã€‚SQL (ç»“æ„åŒ–æŸ¥è¯¢è¯­è¨€)æ˜¯ç”¨äºæ‰§è¡ŒæŸ¥è¯¢çš„è¯­æ³•ã€‚ä½†æ˜¯ SQL è¯­è¨€ä¹ŸåŒ…å«ç”¨äºæ›´æ–°ã€æ’å…¥å’Œåˆ é™¤è®°å½•çš„è¯­æ³•ã€‚ æŸ¥è¯¢å’Œæ›´æ–°æŒ‡ä»¤æ„æˆäº† SQL çš„ DML éƒ¨åˆ†ï¼š SELECT - ä»æ•°æ®åº“è¡¨ä¸­è·å–æ•°æ® UPDATE - æ›´æ–°æ•°æ®åº“è¡¨ä¸­çš„æ•°æ® DELETE - ä»æ•°æ®åº“è¡¨ä¸­åˆ é™¤æ•°æ® INSERT INTO - å‘æ•°æ®åº“è¡¨ä¸­æ’å…¥æ•°æ® SQL çš„æ•°æ®å®šä¹‰è¯­è¨€ (DDL) éƒ¨åˆ†ä½¿æˆ‘ä»¬æœ‰èƒ½åŠ›åˆ›å»ºæˆ–åˆ é™¤è¡¨æ ¼ã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥å®šä¹‰ç´¢å¼•ï¼ˆé”®ï¼‰ï¼Œè§„å®šè¡¨ä¹‹é—´çš„é“¾æ¥ï¼Œä»¥åŠæ–½åŠ è¡¨é—´çš„çº¦æŸã€‚ SQL ä¸­æœ€é‡è¦çš„ DDL è¯­å¥: CREATE DATABASE - åˆ›å»ºæ–°æ•°æ®åº“ ALTER DATABASE - ä¿®æ”¹æ•°æ®åº“ CREATE TABLE - åˆ›å»ºæ–°è¡¨ ALTER TABLE - å˜æ›´ï¼ˆæ”¹å˜ï¼‰æ•°æ®åº“è¡¨ DROP TABLE - åˆ é™¤è¡¨ CREATE INDEX - åˆ›å»ºç´¢å¼•ï¼ˆæœç´¢é”®ï¼‰ DROP INDEX - åˆ é™¤ç´¢å¼• SELECTè¯­å¥SELECT12# SELECT åˆ—åç§° FROM è¡¨åç§°SELECT * FROM students; SELECT DISTINCT123# ç”¨äºè¿”å›å”¯ä¸€ä¸åŒçš„å€¼# SELECT DISTINCT åˆ—åç§° FROM è¡¨åç§°SELECT DISTINCT Company FROM Orders ; WHERE1# SELECT åˆ—åç§° FROM è¡¨åç§° WHERE åˆ— è¿ç®—ç¬¦ å€¼ ORDER BY1SELECT Company, OrderNumber FROM Orders ORDER BY Company DESC, OrderNumber ASC; INSERT INTO123# INSERT INTO table_name (åˆ—1, åˆ—2,...) VALUES (å€¼1, å€¼2,....)INSERT INTO Persons VALUES ('Gates', 'Bill', 'Xuanwumen 10', 'Beijing');INSERT INTO Persons (LastName, Address) VALUES ('Wilson', 'Champs-Elysees'); UPDATE12345# UPDATE è¡¨åç§° SET åˆ—åç§° = æ–°å€¼ WHERE åˆ—åç§° = æŸå€¼# æˆ‘ä»¬ä¸º lastname æ˜¯ \"Wilson\" çš„äººæ·»åŠ  firstnameï¼šUPDATE Person SET FirstName = 'Fred' WHERE LastName = 'Wilson' # æˆ‘ä»¬ä¼šä¿®æ”¹åœ°å€ï¼ˆaddressï¼‰ï¼Œå¹¶æ·»åŠ åŸå¸‚åç§°ï¼ˆcityï¼‰ï¼šUPDATE Person SET Address = 'Zhongshan 23', City = 'Nanjing' WHERE LastName = 'Wilson' DELETE123456# åˆ é™¤è¡Œ# DELETE FROM è¡¨åç§° WHERE åˆ—åç§° = å€¼DELETE FROM Person WHERE LastName = 'Wilson' # åˆ é™¤æ‰€æœ‰è¡ŒDELETE FROM table_nameDELETE * FROM table_name é«˜çº§TOP1234# æˆ‘ä»¬å¸Œæœ›ä»ä¸Šé¢çš„ \"Persons\" è¡¨ä¸­é€‰å–å¤´ä¸¤æ¡è®°å½•SELECT TOP 2 * FROM Persons# æˆ‘ä»¬å¸Œæœ›ä»ä¸Šé¢çš„ \"Persons\" è¡¨ä¸­é€‰å– 50% çš„è®°å½•SELECT TOP 50 PERCENT * FROM Persons LIKELIKE æ“ä½œç¬¦ç”¨äºåœ¨ WHERE å­å¥ä¸­æœç´¢åˆ—ä¸­çš„æŒ‡å®šæ¨¡å¼12345# ä»ä¸Šé¢çš„ \"Persons\" è¡¨ä¸­é€‰å–å±…ä½åœ¨ä»¥ \"N\" å¼€å§‹çš„åŸå¸‚é‡Œçš„äººï¼šSELECT * FROM Persons WHERE City LIKE 'N%'# \"%\" å¯ç”¨äºå®šä¹‰é€šé…ç¬¦ï¼ˆæ¨¡å¼ä¸­ç¼ºå°‘çš„å­—æ¯ï¼‰# ä» \"Persons\" è¡¨ä¸­é€‰å–å±…ä½åœ¨ä¸åŒ…å« \"lon\" çš„åŸå¸‚é‡Œçš„äººï¼šSELECT * FROM Persons WHERE City NOT LIKE '%lon%' é€šé…ç¬¦123# ä»ä¸Šé¢çš„ \"Persons\" è¡¨ä¸­é€‰å–å±…ä½çš„åŸå¸‚ä¸ä»¥ \"A\" æˆ– \"L\" æˆ– \"N\" å¼€å¤´çš„äººï¼šSELECT * FROM PersonsWHERE City LIKE '[!ALN]%' ININ æ“ä½œç¬¦å…è®¸æˆ‘ä»¬åœ¨ WHERE å­å¥ä¸­è§„å®šå¤šä¸ªå€¼123# ä»ä¸Šè¡¨ä¸­é€‰å–å§“æ°ä¸º Adams å’Œ Carter çš„äººï¼šSELECT * FROM PersonsWHERE LastName IN ('Adams','Carter') BETWEENBETWEEN æ“ä½œç¬¦åœ¨ WHERE å­å¥ä¸­ä½¿ç”¨ï¼Œä½œç”¨æ˜¯é€‰å–ä»‹äºä¸¤ä¸ªå€¼ä¹‹é—´çš„æ•°æ®èŒƒå›´ã€‚12345678# ä»¥å­—æ¯é¡ºåºæ˜¾ç¤ºä»‹äº \"Adams\"ï¼ˆåŒ…æ‹¬ï¼‰å’Œ \"Carter\"ï¼ˆä¸åŒ…æ‹¬ï¼‰ä¹‹é—´çš„äººï¼Œè¯·ä½¿ç”¨ä¸‹é¢çš„ SQLï¼šSELECT * FROM PersonsWHERE LastNameBETWEEN 'Adams' AND 'Carter'# ä½¿ç”¨ä¸Šé¢çš„ä¾‹å­æ˜¾ç¤ºèŒƒå›´ä¹‹å¤–çš„äººï¼Œè¯·ä½¿ç”¨ NOT æ“ä½œç¬¦ï¼šSELECT * FROM PersonsWHERE LastNameNOT BETWEEN 'Adams' AND 'Carter' ä½¿ç”¨åˆ«å12SELECT LastName AS Family, FirstName AS NameFROM Persons JOINjoin ç”¨äºæ ¹æ®ä¸¤ä¸ªæˆ–å¤šä¸ªè¡¨ä¸­çš„åˆ—ä¹‹é—´çš„å…³ç³»ï¼Œä»è¿™äº›è¡¨ä¸­æŸ¥è¯¢æ•°æ®ã€‚ å…ˆç¡®å®šä¸»è¡¨ï¼Œä»ç„¶ä½¿ç”¨FROM &lt;è¡¨1&gt;çš„è¯­æ³•ï¼› å†ç¡®å®šéœ€è¦è¿æ¥çš„è¡¨ï¼Œä½¿ç”¨INNER JOIN &lt;è¡¨2&gt;çš„è¯­æ³•ï¼› ç„¶åç¡®å®šè¿æ¥æ¡ä»¶ï¼Œä½¿ç”¨ON &lt;æ¡ä»¶â€¦&gt;ï¼Œè¿™é‡Œçš„æ¡ä»¶æ˜¯s.class_id = c.idï¼Œè¡¨ç¤ºstudentsè¡¨çš„class_idåˆ—ä¸classesè¡¨çš„idåˆ—ç›¸åŒçš„è¡Œéœ€è¦è¿æ¥ï¼› å¯é€‰ï¼šåŠ ä¸ŠWHEREå­å¥ã€ORDER BYç­‰å­å¥ã€‚123456# åˆ—å‡ºæ‰€æœ‰äººçš„å®šè´­ï¼Œå¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ SELECT è¯­å¥ï¼šSELECT Persons.LastName, Persons.FirstName, Orders.OrderNoFROM PersonsINNER JOIN OrdersON Persons.Id_P = Orders.Id_PORDER BY Persons.LastName UNIONUNION æ“ä½œç¬¦ç”¨äºåˆå¹¶ä¸¤ä¸ªæˆ–å¤šä¸ª SELECT è¯­å¥çš„ç»“æœé›†12345# åˆ—å‡ºæ‰€æœ‰åœ¨ä¸­å›½å’Œç¾å›½çš„ä¸åŒçš„é›‡å‘˜åï¼šSELECT E_Name FROM Employees_ChinaUNIONSELECT E_Name FROM Employees_USA# UNION ALL å…è®¸é‡å¤ SELECT INTO SELECT INTO è¯­å¥å¯ç”¨äºåˆ›å»ºè¡¨çš„å¤‡ä»½å¤ä»¶ SELECT INTO è¯­å¥ä»ä¸€ä¸ªè¡¨ä¸­é€‰å–æ•°æ®ï¼Œç„¶åæŠŠæ•°æ®æ’å…¥å¦ä¸€ä¸ªè¡¨ä¸­ã€‚ SELECT INTO è¯­å¥å¸¸ç”¨äºåˆ›å»ºè¡¨çš„å¤‡ä»½å¤ä»¶æˆ–è€…ç”¨äºå¯¹è®°å½•è¿›è¡Œå­˜æ¡£ã€‚12345678910# å¤‡ä»½SELECT *INTO Persons_backupFROM Persons# åˆ›å»ºä¸€ä¸ªåä¸º \"Persons_Order_Backup\" çš„æ–°è¡¨ï¼Œå…¶ä¸­åŒ…å«äº†ä» Persons å’Œ Orders ä¸¤ä¸ªè¡¨ä¸­å–å¾—çš„ä¿¡æ¯ï¼šSELECT Persons.LastName,Orders.OrderNoINTO Persons_Order_BackupFROM PersonsINNER JOIN OrdersON Persons.Id_P = Orders.Id_P CREATE DATABASE12# åˆ›å»ºæ•°æ®åº“CREATE DATABASE my_db CREATE TABLE12345678CREATE TABLE Persons(Id_P int,LastName varchar(255),FirstName varchar(255),Address varchar(255),City varchar(255)) çº¦æŸ (Constraints) NOT NULL UNIQUE PRIMARY KEY FOREIGN KEY CHECK DEFAULT NOT NULL123456789# å¼ºåˆ¶åˆ—ä¸æ¥å— NULL å€¼CREATE TABLE Persons(Id_P int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255)) UNIQUE123456789CREATE TABLE Persons(Id_P int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255),UNIQUE (Id_P)) å½“è¡¨å·²è¢«åˆ›å»ºæ—¶ï¼Œå¦‚éœ€åœ¨ â€œId_Pâ€ åˆ—åˆ›å»º UNIQUE çº¦æŸï¼Œè¯·ä½¿ç”¨ä¸‹åˆ— SQLï¼š12ALTER TABLE PersonsADD UNIQUE (Id_P) PRIMARY KEY PRIMARY KEY çº¦æŸå”¯ä¸€æ ‡è¯†æ•°æ®åº“è¡¨ä¸­çš„æ¯æ¡è®°å½•ã€‚ ä¸»é”®å¿…é¡»åŒ…å«å”¯ä¸€çš„å€¼ã€‚ ä¸»é”®åˆ—ä¸èƒ½åŒ…å« NULL å€¼ã€‚ æ¯ä¸ªè¡¨éƒ½åº”è¯¥æœ‰ä¸€ä¸ªä¸»é”®ï¼Œå¹¶ä¸”æ¯ä¸ªè¡¨åªèƒ½æœ‰ä¸€ä¸ªä¸»é”®ã€‚123456789CREATE TABLE Persons(Id_P int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255),PRIMARY KEY (Id_P)) å¦‚æœåœ¨è¡¨å·²å­˜åœ¨çš„æƒ…å†µä¸‹ä¸º â€œId_Pâ€ åˆ—åˆ›å»º PRIMARY KEY çº¦æŸï¼Œè¯·ä½¿ç”¨ä¸‹é¢çš„ SQLï¼š12ALTER TABLE PersonsADD PRIMARY KEY (Id_P) DEFAULTDEFAULT çº¦æŸç”¨äºå‘åˆ—ä¸­æ’å…¥é»˜è®¤å€¼ã€‚12345678CREATE TABLE Persons(Id_P int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255) DEFAULT 'Sandnes') CREATE INDEX CREATE INDEX è¯­å¥ç”¨äºåœ¨è¡¨ä¸­åˆ›å»ºç´¢å¼•ã€‚ åœ¨ä¸è¯»å–æ•´ä¸ªè¡¨çš„æƒ…å†µä¸‹ï¼Œç´¢å¼•ä½¿æ•°æ®åº“åº”ç”¨ç¨‹åºå¯ä»¥æ›´å¿«åœ°æŸ¥æ‰¾æ•°æ®ã€‚123456# åœ¨è¡¨ä¸Šåˆ›å»ºä¸€ä¸ªç®€å•çš„ç´¢å¼•ã€‚å…è®¸ä½¿ç”¨é‡å¤çš„å€¼ï¼šCREATE INDEX index_nameON table_name (column_name)# åœ¨è¡¨ä¸Šåˆ›å»ºä¸€ä¸ªå”¯ä¸€çš„ç´¢å¼•CREATE UNIQUE INDEX index_nameON table_name (column_name) DROPé€šè¿‡ä½¿ç”¨ DROP è¯­å¥ï¼Œå¯ä»¥è½»æ¾åœ°åˆ é™¤ç´¢å¼•ã€è¡¨å’Œæ•°æ®åº“ã€‚1234DROP TABLE è¡¨åç§°DROP DATABASE æ•°æ®åº“åç§°ä½¿ç”¨ TRUNCATE TABLE å‘½ä»¤ï¼ˆä»…ä»…åˆ é™¤è¡¨æ ¼ä¸­çš„æ•°æ®ï¼‰ï¼šTRUNCATE TABLE è¡¨åç§° ALTER TABLEALTER TABLE è¯­å¥ç”¨äºåœ¨å·²æœ‰çš„è¡¨ä¸­æ·»åŠ ã€ä¿®æ”¹æˆ–åˆ é™¤åˆ—ã€‚123456789# å¦‚éœ€åœ¨è¡¨ä¸­æ·»åŠ åˆ—ï¼Œè¯·ä½¿ç”¨ä¸‹åˆ—è¯­æ³•:ALTER TABLE table_nameADD column_name datatype# è¦åˆ é™¤è¡¨ä¸­çš„åˆ—ï¼Œè¯·ä½¿ç”¨ä¸‹åˆ—è¯­æ³•ï¼šALTER TABLE table_name DROP COLUMN column_name# è¦æ”¹å˜è¡¨ä¸­åˆ—çš„æ•°æ®ç±»å‹ï¼Œè¯·ä½¿ç”¨ä¸‹åˆ—è¯­æ³•ï¼šALTER TABLE table_nameALTER COLUMN column_name datatype 123# åœ¨è¡¨ \"Persons\" ä¸­æ·»åŠ ä¸€ä¸ªåä¸º \"Birthday\" çš„æ–°åˆ—ALTER TABLE PersonsADD Birthday date AUTO INCREMENTAuto-increment ä¼šåœ¨æ–°è®°å½•æ’å…¥è¡¨ä¸­æ—¶ç”Ÿæˆä¸€ä¸ªå”¯ä¸€çš„æ•°å­—ã€‚12345678910# æŠŠ \"Persons\" è¡¨ä¸­çš„ \"P_Id\" åˆ—å®šä¹‰ä¸º auto-increment ä¸»é”®ï¼šCREATE TABLE Persons(P_Id int NOT NULL AUTO_INCREMENT,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255),PRIMARY KEY (P_Id)) VIEWè§†å›¾æ˜¯åŸºäº SQL è¯­å¥çš„ç»“æœé›†çš„å¯è§†åŒ–çš„è¡¨ã€‚ NULL123# é€‰å–åœ¨ \"Address\" åˆ—ä¸­å¸¦æœ‰ NULL å€¼çš„è®°å½•:SELECT LastName,FirstName,Address FROM PersonsWHERE Address IS NULL","link":"/2019/02/21/sql/"}],"tags":[{"name":"æœºå™¨å­¦ä¹ ","slug":"æœºå™¨å­¦ä¹ ","link":"/tags/æœºå™¨å­¦ä¹ /"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"ç®—æ³•","slug":"ç®—æ³•","link":"/tags/ç®—æ³•/"},{"name":"SQL","slug":"SQL","link":"/tags/SQL/"}],"categories":[{"name":"machine learning","slug":"machine-learning","link":"/categories/machine-learning/"},{"name":"Kaggle","slug":"Kaggle","link":"/categories/Kaggle/"},{"name":"python","slug":"python","link":"/categories/python/"},{"name":"ç®—æ³•","slug":"ç®—æ³•","link":"/categories/ç®—æ³•/"}]}